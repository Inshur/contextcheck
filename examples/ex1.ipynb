{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1\n",
    "\n",
    "In this notebook we will present you a simple case of using contextcheck to validate llm responses.\n",
    "\n",
    "We will talk about:\n",
    "- Configuration\n",
    "- Test Scenario\n",
    "- Test Steps\n",
    "- Running the Test Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add optional jinja2 templating section or a remark with a link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install contextcheck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextcheck import TestScenario\n",
    "from contextcheck.executors.executor import Executor # NOTE RB: Maybe Executor should be at the most outer layer for import\n",
    "import yaml\n",
    "import rich"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "\n",
    "Mostly used to showcase the results of ran tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_test_step_results(test_scenario: TestScenario):\n",
    "    print(\"-\"*12)\n",
    "    for step in test_scenario.steps:\n",
    "        print(f\"Name: {step.name}; Result: {step.result}\\n\")\n",
    "        for assertion in step.asserts:\n",
    "            assertion_dumped = assertion.model_dump()\n",
    "            assertion_ = assertion.eval if \"eval\" in assertion_dumped else assertion.assertion\n",
    "            print(f'Assertion: \"{assertion_}\", Result: {assertion.result}')\n",
    "        print(\"-\"*12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send default request\n",
    "\n",
    "Let's initially create a simple yaml that we will use to send a dummy request to OpenAI.\n",
    "\n",
    "*When config is empty then OpenAI's gpt-4o-mini is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define configuration in yaml - for demonstration purposes it's done in notebook\n",
    "yaml_string = \"\"\"\n",
    "config:\n",
    "\n",
    "steps:\n",
    "   - What is the capital of Poland?\n",
    "\"\"\"\n",
    "\n",
    "yaml_from_string = yaml.safe_load(yaml_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test scenario\n",
    "test_scenario = TestScenario.model_validate(yaml_from_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestScenario</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">steps</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestStep</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'What is the capital of Poland?'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'What is the capital of Poland?'</span><span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">asserts</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">config</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">endpoint_under_test</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">kind</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">additional_headers</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">provider</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">top_k</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">use_ranker</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">collection_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">default_request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">eval_endpoint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">filename</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mTestScenario\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33msteps\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mTestStep\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mname\u001b[0m=\u001b[32m'What is the capital of Poland?'\u001b[0m,\n",
       "            \u001b[33mrequest\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'What is the capital of Poland?'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[33mresponse\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33masserts\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "            \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mconfig\u001b[0m=\u001b[1;35mTestConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mendpoint_under_test\u001b[0m=\u001b[1;35mEndpointConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mkind\u001b[0m=\u001b[32m'openai'\u001b[0m,\n",
       "            \u001b[33murl\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "            \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-mini'\u001b[0m,\n",
       "            \u001b[33madditional_headers\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mprovider\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtemperature\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtop_k\u001b[0m=\u001b[1;36m3\u001b[0m,\n",
       "            \u001b[33muse_ranker\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "            \u001b[33mcollection_name\u001b[0m=\u001b[32m'default'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[33mdefault_request\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33meval_endpoint\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mfilename\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize test scenario\n",
    "rich.print(test_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create executor that uses test scenario\n",
    "executor = Executor(test_scenario=test_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-26 15:20:23.774\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.executors.executor\u001b[0m:\u001b[36mrun_all\u001b[0m:\u001b[36m41\u001b[0m - \u001b[1mRunning scenario\u001b[0m\n",
      "\u001b[32m2024-09-26 15:20:23.775\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mname='What is the capital of Poland?' request=RequestBase(message='What is the capital of Poland?') response=None asserts=[] result=None\u001b[0m\n",
      "\u001b[32m2024-09-26 15:20:23.776\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mmessage='What is the capital of Poland?'\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-26 15:20:24.413\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mmessage='The capital of Poland is Warsaw.' stats=ResponseStats(tokens_request=14, tokens_response=7, tokens_total=21, conn_start_time=25028.39479685, conn_end_time=25029.029330006, conn_duration=0.6345331560005434) id='chatcmpl-ABihsRTVsu13ak7iVreYxvEilxmGE' choices=[{'finish_reason': 'stop', 'index': 0, 'logprobs': None, 'message': {'content': 'The capital of Poland is Warsaw.', 'role': 'assistant', 'refusal': None}}] created=1727356824 model='gpt-4o-mini-2024-07-18' object='chat.completion' system_fingerprint='fp_1bb46167f9' usage={'completion_tokens': 7, 'prompt_tokens': 14, 'total_tokens': 21, 'completion_tokens_details': {'reasoning_tokens': 0}} config=EndpointConfig(kind='openai', url='', model='gpt-4o-mini', additional_headers={}, provider=None, temperature=None, max_tokens=None, top_k=3, use_ranker=True, collection_name='default')\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run all test steps\n",
    "executor.run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestScenario</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">steps</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestStep</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'What is the capital of Poland?'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'What is the capital of Poland?'</span><span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseModel</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The capital of Poland is Warsaw.'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">stats</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseStats</span><span style=\"font-weight: bold\">(</span>\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">tokens_request</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">tokens_response</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">tokens_total</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_start_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25028.39479685</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_end_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25029.029330006</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_duration</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6345331560005434</span>\n",
       "                <span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-ABihsRTVsu13ak7iVreYxvEilxmGE'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "                    <span style=\"font-weight: bold\">{</span>\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'finish_reason'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'logprobs'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'message'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'The capital of Poland is Warsaw.'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'refusal'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "                        <span style=\"font-weight: bold\">}</span>\n",
       "                    <span style=\"font-weight: bold\">}</span>\n",
       "                <span style=\"font-weight: bold\">]</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1727356824</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'fp_1bb46167f9'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens_details'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'reasoning_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">}</span>\n",
       "                <span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">config</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">kind</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini'</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">additional_headers</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">provider</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">top_k</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">use_ranker</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">collection_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>\n",
       "                <span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">asserts</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">config</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">endpoint_under_test</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">kind</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">additional_headers</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">provider</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">top_k</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">use_ranker</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">collection_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">default_request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">eval_endpoint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">filename</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mTestScenario\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33msteps\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mTestStep\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mname\u001b[0m=\u001b[32m'What is the capital of Poland?'\u001b[0m,\n",
       "            \u001b[33mrequest\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'What is the capital of Poland?'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[33mresponse\u001b[0m=\u001b[1;35mResponseModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mmessage\u001b[0m=\u001b[32m'The capital of Poland is Warsaw.'\u001b[0m,\n",
       "                \u001b[33mstats\u001b[0m=\u001b[1;35mResponseStats\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[33mtokens_request\u001b[0m=\u001b[1;36m14\u001b[0m,\n",
       "                    \u001b[33mtokens_response\u001b[0m=\u001b[1;36m7\u001b[0m,\n",
       "                    \u001b[33mtokens_total\u001b[0m=\u001b[1;36m21\u001b[0m,\n",
       "                    \u001b[33mconn_start_time\u001b[0m=\u001b[1;36m25028\u001b[0m\u001b[1;36m.39479685\u001b[0m,\n",
       "                    \u001b[33mconn_end_time\u001b[0m=\u001b[1;36m25029\u001b[0m\u001b[1;36m.029330006\u001b[0m,\n",
       "                    \u001b[33mconn_duration\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.6345331560005434\u001b[0m\n",
       "                \u001b[1m)\u001b[0m,\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-ABihsRTVsu13ak7iVreYxvEilxmGE'\u001b[0m,\n",
       "                \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "                    \u001b[1m{\u001b[0m\n",
       "                        \u001b[32m'finish_reason'\u001b[0m: \u001b[32m'stop'\u001b[0m,\n",
       "                        \u001b[32m'index'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "                        \u001b[32m'logprobs'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "                        \u001b[32m'message'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                            \u001b[32m'content'\u001b[0m: \u001b[32m'The capital of Poland is Warsaw.'\u001b[0m,\n",
       "                            \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,\n",
       "                            \u001b[32m'refusal'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "                        \u001b[1m}\u001b[0m\n",
       "                    \u001b[1m}\u001b[0m\n",
       "                \u001b[1m]\u001b[0m,\n",
       "                \u001b[33mcreated\u001b[0m=\u001b[1;36m1727356824\u001b[0m,\n",
       "                \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m,\n",
       "                \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,\n",
       "                \u001b[33msystem_fingerprint\u001b[0m=\u001b[32m'fp_1bb46167f9'\u001b[0m,\n",
       "                \u001b[33musage\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                    \u001b[32m'completion_tokens'\u001b[0m: \u001b[1;36m7\u001b[0m,\n",
       "                    \u001b[32m'prompt_tokens'\u001b[0m: \u001b[1;36m14\u001b[0m,\n",
       "                    \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m21\u001b[0m,\n",
       "                    \u001b[32m'completion_tokens_details'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'reasoning_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m\n",
       "                \u001b[1m}\u001b[0m,\n",
       "                \u001b[33mconfig\u001b[0m=\u001b[1;35mEndpointConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[33mkind\u001b[0m=\u001b[32m'openai'\u001b[0m,\n",
       "                    \u001b[33murl\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "                    \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-mini'\u001b[0m,\n",
       "                    \u001b[33madditional_headers\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                    \u001b[33mprovider\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[33mtemperature\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[33mtop_k\u001b[0m=\u001b[1;36m3\u001b[0m,\n",
       "                    \u001b[33muse_ranker\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "                    \u001b[33mcollection_name\u001b[0m=\u001b[32m'default'\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[33masserts\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "            \u001b[33mresult\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mconfig\u001b[0m=\u001b[1;35mTestConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mendpoint_under_test\u001b[0m=\u001b[1;35mEndpointConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mkind\u001b[0m=\u001b[32m'openai'\u001b[0m,\n",
       "            \u001b[33murl\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "            \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-mini'\u001b[0m,\n",
       "            \u001b[33madditional_headers\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mprovider\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtemperature\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtop_k\u001b[0m=\u001b[1;36m3\u001b[0m,\n",
       "            \u001b[33muse_ranker\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "            \u001b[33mcollection_name\u001b[0m=\u001b[32m'default'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[33mdefault_request\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33meval_endpoint\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mresult\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[33mfilename\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Once more visualize the test scenario to see the changes\n",
    "rich.print(test_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of Poland is Warsaw.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Response from llm\n",
    "test_scenario.steps[0].response.message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config update\n",
    "\n",
    "We initially left the config empty, but we can easily populate it with configuration that best fits our needs.\n",
    "\n",
    "For defining the connection to the llm or rag system we use `endpoint_under_test`. For demo purposes we will use one of OpenAI's models which are already implemented by default. For more information please visit [TODO - Link to config]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_string = \"\"\"\n",
    "config:\n",
    "   endpoint_under_test:\n",
    "      kind: openai\n",
    "      model: gpt-4o   \n",
    "\n",
    "steps:\n",
    "   - What is the capital of Poland?\n",
    "\"\"\"\n",
    "\n",
    "yaml_from_string = yaml.safe_load(yaml_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test scenario\n",
    "test_scenario = TestScenario.model_validate(yaml_from_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestScenario</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">steps</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestStep</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'What is the capital of Poland?'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'What is the capital of Poland?'</span><span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">asserts</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">config</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">endpoint_under_test</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">kind</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">additional_headers</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">provider</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">top_k</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">use_ranker</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">collection_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">default_request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">eval_endpoint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">filename</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mTestScenario\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33msteps\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mTestStep\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mname\u001b[0m=\u001b[32m'What is the capital of Poland?'\u001b[0m,\n",
       "            \u001b[33mrequest\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'What is the capital of Poland?'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[33mresponse\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33masserts\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "            \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mconfig\u001b[0m=\u001b[1;35mTestConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mendpoint_under_test\u001b[0m=\u001b[1;35mEndpointConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mkind\u001b[0m=\u001b[32m'openai'\u001b[0m,\n",
       "            \u001b[33murl\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "            \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o'\u001b[0m,\n",
       "            \u001b[33madditional_headers\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mprovider\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtemperature\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtop_k\u001b[0m=\u001b[1;36m3\u001b[0m,\n",
       "            \u001b[33muse_ranker\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "            \u001b[33mcollection_name\u001b[0m=\u001b[32m'default'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[33mdefault_request\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33meval_endpoint\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mfilename\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize test scenario\n",
    "# Note the change in config from gpt-4o-mini to gpt-4o\n",
    "rich.print(test_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create executor that uses test scenario\n",
    "executor = Executor(test_scenario=test_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-26 15:20:24.684\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.executors.executor\u001b[0m:\u001b[36mrun_all\u001b[0m:\u001b[36m41\u001b[0m - \u001b[1mRunning scenario\u001b[0m\n",
      "\u001b[32m2024-09-26 15:20:24.687\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mname='What is the capital of Poland?' request=RequestBase(message='What is the capital of Poland?') response=None asserts=[] result=None\u001b[0m\n",
      "\u001b[32m2024-09-26 15:20:24.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mmessage='What is the capital of Poland?'\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-26 15:20:25.398\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mmessage='The capital of Poland is Warsaw.' stats=ResponseStats(tokens_request=14, tokens_response=7, tokens_total=21, conn_start_time=25029.309263794, conn_end_time=25030.014328409, conn_duration=0.705064615001902) id='chatcmpl-ABihtG9ggk95ihNvIXqrXJUBtLri1' choices=[{'finish_reason': 'stop', 'index': 0, 'logprobs': None, 'message': {'content': 'The capital of Poland is Warsaw.', 'role': 'assistant', 'refusal': None}}] created=1727356825 model='gpt-4o-2024-05-13' object='chat.completion' system_fingerprint='fp_e375328146' usage={'completion_tokens': 7, 'prompt_tokens': 14, 'total_tokens': 21, 'completion_tokens_details': {'reasoning_tokens': 0}} config=EndpointConfig(kind='openai', url='', model='gpt-4o', additional_headers={}, provider=None, temperature=None, max_tokens=None, top_k=3, use_ranker=True, collection_name='default')\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "executor.run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of Poland is Warsaw.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Response from llm\n",
    "test_scenario.steps[0].response.message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple scenario\n",
    "\n",
    "Lets create a simple test scenario which will help you understand the working of contextcheck.\n",
    "We will use simple asserts which are based on python's `eval` build-in functionality.\n",
    "\n",
    "\n",
    "We believe it's also a good place to introduce the nomenclature for test steps.\n",
    "\n",
    "Each step can by defined by its `name` (optional), `request` and `asserts` (optional):\n",
    "- `name` is a name of the test step\n",
    "- `request` is a message to an llm\n",
    "- `asserts` is a list of assertions done on llm response\n",
    "\n",
    "NOTE: By default each assert is treated as an `eval` assertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reuse yaml from previous example and extend it\n",
    "yaml_string = \"\"\"\n",
    "config:\n",
    "   endpoint_under_test:\n",
    "      kind: openai\n",
    "      model: gpt-4o   \n",
    "\n",
    "steps:\n",
    "   - name: Write sucess\n",
    "     request: 'Please write only \"success\" as a response'\n",
    "     asserts:\n",
    "        - '\"success\" == response.message'\n",
    "        - 'response.stats.conn_duration < 10'\n",
    "\"\"\"\n",
    "\n",
    "yaml_from_string = yaml.safe_load(yaml_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test scenario\n",
    "test_scenario = TestScenario.model_validate(yaml_from_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestScenario</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">steps</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestStep</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Write sucess'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Please write only \"success\" as a response'</span><span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">asserts</span>=<span style=\"font-weight: bold\">[</span>\n",
       "                <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionEval</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eval</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'\"success\" == response.message'</span><span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionEval</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eval</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'response.stats.conn_duration &lt; 10'</span><span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">]</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">config</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">endpoint_under_test</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">kind</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">additional_headers</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">provider</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">top_k</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">use_ranker</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">collection_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">default_request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">eval_endpoint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">filename</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mTestScenario\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33msteps\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mTestStep\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mname\u001b[0m=\u001b[32m'Write sucess'\u001b[0m,\n",
       "            \u001b[33mrequest\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'Please write only \"success\" as a response'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[33mresponse\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33masserts\u001b[0m=\u001b[1m[\u001b[0m\n",
       "                \u001b[1;35mAssertionEval\u001b[0m\u001b[1m(\u001b[0m\u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33meval\u001b[0m=\u001b[32m'\"success\" == response.message'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "                \u001b[1;35mAssertionEval\u001b[0m\u001b[1m(\u001b[0m\u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33meval\u001b[0m=\u001b[32m'response.stats.conn_duration < 10'\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m]\u001b[0m,\n",
       "            \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mconfig\u001b[0m=\u001b[1;35mTestConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mendpoint_under_test\u001b[0m=\u001b[1;35mEndpointConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mkind\u001b[0m=\u001b[32m'openai'\u001b[0m,\n",
       "            \u001b[33murl\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "            \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o'\u001b[0m,\n",
       "            \u001b[33madditional_headers\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mprovider\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtemperature\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtop_k\u001b[0m=\u001b[1;36m3\u001b[0m,\n",
       "            \u001b[33muse_ranker\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "            \u001b[33mcollection_name\u001b[0m=\u001b[32m'default'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[33mdefault_request\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33meval_endpoint\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mfilename\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize test scenario\n",
    "rich.print(test_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create executor that uses test scenario\n",
    "executor = Executor(test_scenario=test_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-26 15:20:26.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.executors.executor\u001b[0m:\u001b[36mrun_all\u001b[0m:\u001b[36m41\u001b[0m - \u001b[1mRunning scenario\u001b[0m\n",
      "\u001b[32m2024-09-26 15:20:26.762\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mname='Write sucess' request=RequestBase(message='Please write only \"success\" as a response') response=None asserts=[AssertionEval(result=None, eval='\"success\" == response.message'), AssertionEval(result=None, eval='response.stats.conn_duration < 10')] result=None\u001b[0m\n",
      "\u001b[32m2024-09-26 15:20:26.763\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mmessage='Please write only \"success\" as a response'\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-26 15:20:27.261\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mmessage='success' stats=ResponseStats(tokens_request=16, tokens_response=1, tokens_total=17, conn_start_time=25031.381730285, conn_end_time=25031.877946775, conn_duration=0.49621648999891477) id='chatcmpl-ABihvJYAhRnRUmB3wWjzOx1D8F2Bv' choices=[{'finish_reason': 'stop', 'index': 0, 'logprobs': None, 'message': {'content': 'success', 'role': 'assistant', 'refusal': None}}] created=1727356827 model='gpt-4o-2024-05-13' object='chat.completion' system_fingerprint='fp_e375328146' usage={'completion_tokens': 1, 'prompt_tokens': 16, 'total_tokens': 17, 'completion_tokens_details': {'reasoning_tokens': 0}} config=EndpointConfig(kind='openai', url='', model='gpt-4o', additional_headers={}, provider=None, temperature=None, max_tokens=None, top_k=3, use_ranker=True, collection_name='default')\u001b[0m\n",
      "\u001b[32m2024-09-26 15:20:27.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mresult=True eval='\"success\" == response.message'\u001b[0m\n",
      "\u001b[32m2024-09-26 15:20:27.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mresult=True eval='response.stats.conn_duration < 10'\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "executor.run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestScenario</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">steps</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestStep</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Write sucess'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Please write only \"success\" as a response'</span><span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseModel</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'success'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">stats</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseStats</span><span style=\"font-weight: bold\">(</span>\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">tokens_request</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">tokens_response</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">tokens_total</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_start_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25031.381730285</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_end_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25031.877946775</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_duration</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.49621648999891477</span>\n",
       "                <span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-ABihvJYAhRnRUmB3wWjzOx1D8F2Bv'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "                    <span style=\"font-weight: bold\">{</span>\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'finish_reason'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'logprobs'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'message'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'success'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'refusal'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>\n",
       "                    <span style=\"font-weight: bold\">}</span>\n",
       "                <span style=\"font-weight: bold\">]</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1727356827</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-2024-05-13'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'fp_e375328146'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens_details'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'reasoning_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">}</span>\n",
       "                <span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">config</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">kind</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o'</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">additional_headers</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">provider</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">top_k</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">use_ranker</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">collection_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>\n",
       "                <span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">asserts</span>=<span style=\"font-weight: bold\">[</span>\n",
       "                <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionEval</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eval</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'\"success\" == response.message'</span><span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionEval</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eval</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'response.stats.conn_duration &lt; 10'</span><span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">]</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">config</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">endpoint_under_test</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">kind</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">additional_headers</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">provider</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">top_k</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">use_ranker</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">collection_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">default_request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">eval_endpoint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">filename</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mTestScenario\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33msteps\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mTestStep\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mname\u001b[0m=\u001b[32m'Write sucess'\u001b[0m,\n",
       "            \u001b[33mrequest\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'Please write only \"success\" as a response'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[33mresponse\u001b[0m=\u001b[1;35mResponseModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mmessage\u001b[0m=\u001b[32m'success'\u001b[0m,\n",
       "                \u001b[33mstats\u001b[0m=\u001b[1;35mResponseStats\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[33mtokens_request\u001b[0m=\u001b[1;36m16\u001b[0m,\n",
       "                    \u001b[33mtokens_response\u001b[0m=\u001b[1;36m1\u001b[0m,\n",
       "                    \u001b[33mtokens_total\u001b[0m=\u001b[1;36m17\u001b[0m,\n",
       "                    \u001b[33mconn_start_time\u001b[0m=\u001b[1;36m25031\u001b[0m\u001b[1;36m.381730285\u001b[0m,\n",
       "                    \u001b[33mconn_end_time\u001b[0m=\u001b[1;36m25031\u001b[0m\u001b[1;36m.877946775\u001b[0m,\n",
       "                    \u001b[33mconn_duration\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.49621648999891477\u001b[0m\n",
       "                \u001b[1m)\u001b[0m,\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-ABihvJYAhRnRUmB3wWjzOx1D8F2Bv'\u001b[0m,\n",
       "                \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "                    \u001b[1m{\u001b[0m\n",
       "                        \u001b[32m'finish_reason'\u001b[0m: \u001b[32m'stop'\u001b[0m,\n",
       "                        \u001b[32m'index'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "                        \u001b[32m'logprobs'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "                        \u001b[32m'message'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'content'\u001b[0m: \u001b[32m'success'\u001b[0m, \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m, \u001b[32m'refusal'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m\n",
       "                    \u001b[1m}\u001b[0m\n",
       "                \u001b[1m]\u001b[0m,\n",
       "                \u001b[33mcreated\u001b[0m=\u001b[1;36m1727356827\u001b[0m,\n",
       "                \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-2024-05-13'\u001b[0m,\n",
       "                \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,\n",
       "                \u001b[33msystem_fingerprint\u001b[0m=\u001b[32m'fp_e375328146'\u001b[0m,\n",
       "                \u001b[33musage\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                    \u001b[32m'completion_tokens'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "                    \u001b[32m'prompt_tokens'\u001b[0m: \u001b[1;36m16\u001b[0m,\n",
       "                    \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m17\u001b[0m,\n",
       "                    \u001b[32m'completion_tokens_details'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'reasoning_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m\n",
       "                \u001b[1m}\u001b[0m,\n",
       "                \u001b[33mconfig\u001b[0m=\u001b[1;35mEndpointConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[33mkind\u001b[0m=\u001b[32m'openai'\u001b[0m,\n",
       "                    \u001b[33murl\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "                    \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o'\u001b[0m,\n",
       "                    \u001b[33madditional_headers\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                    \u001b[33mprovider\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[33mtemperature\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[33mtop_k\u001b[0m=\u001b[1;36m3\u001b[0m,\n",
       "                    \u001b[33muse_ranker\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "                    \u001b[33mcollection_name\u001b[0m=\u001b[32m'default'\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[33masserts\u001b[0m=\u001b[1m[\u001b[0m\n",
       "                \u001b[1;35mAssertionEval\u001b[0m\u001b[1m(\u001b[0m\u001b[33mresult\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33meval\u001b[0m=\u001b[32m'\"success\" == response.message'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "                \u001b[1;35mAssertionEval\u001b[0m\u001b[1m(\u001b[0m\u001b[33mresult\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33meval\u001b[0m=\u001b[32m'response.stats.conn_duration < 10'\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m]\u001b[0m,\n",
       "            \u001b[33mresult\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mconfig\u001b[0m=\u001b[1;35mTestConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mendpoint_under_test\u001b[0m=\u001b[1;35mEndpointConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mkind\u001b[0m=\u001b[32m'openai'\u001b[0m,\n",
       "            \u001b[33murl\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "            \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o'\u001b[0m,\n",
       "            \u001b[33madditional_headers\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mprovider\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtemperature\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtop_k\u001b[0m=\u001b[1;36m3\u001b[0m,\n",
       "            \u001b[33muse_ranker\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "            \u001b[33mcollection_name\u001b[0m=\u001b[32m'default'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[33mdefault_request\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33meval_endpoint\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mresult\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[33mfilename\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rich.print(test_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "Name: Write sucess; Result: True\n",
      "\n",
      "Assertion: \"\"success\" == response.message\", Result: True\n",
      "Assertion: \"response.stats.conn_duration < 10\", Result: True\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "# Show the result\n",
    "show_test_step_results(test_scenario=test_scenario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario extension\n",
    "\n",
    "Having introduction under our belt we will extend the already built scenario by new types of assertions and explain more in depth the needed topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explain config\n",
    "\n",
    "To extend our scenario we need to introduce new config features that are needed for some of the asertions.\n",
    "\n",
    "In short, config defines llm (or Rag system) connection. We provide several popular llm providers implementations which lets you be productive from the start. For more info about them please go to [Link here].\n",
    "\n",
    "There are three components used in config:\n",
    "1. `endpoint_under_test` - defines the tested endpoint\n",
    "2. `default_request` - defines the defaults for both the `endpoint_under_test` and `eval_endpoint` (TODO: Please someone confirm that)\n",
    "3. `eval_endpoint` - defines the endpoint which is used for evaluating the responses from `endpoint_under_test`\n",
    "\n",
    "For more infromation about configuration please go to [TODO - INSERT LINK HERE]\n",
    "\n",
    "TODO: What's the purpose of `default_request` when the same configuration can be given to `endpoint_under_test` or `eval_endpoint`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'config': {'endpoint_under_test': {'kind': 'openai',\n",
       "   'model': 'gpt-4o-mini',\n",
       "   'temperature': 0.2},\n",
       "  'eval_endpoint': {'kind': 'openai', 'model': 'gpt-4o', 'temperature': 0.0}},\n",
       " 'steps': [{'name': 'Test model grading QA evaluator',\n",
       "   'request': {'message': 'Please write a 5 line poem about AI.'},\n",
       "   'asserts': [{'llm_metric': 'model-grading-qa',\n",
       "     'assertion': 'Text should be a poem about AI.'},\n",
       "    {'llm_metric': 'model-grading-qa',\n",
       "     'assertion': 'Text should be a report on taxes.'}]}]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets use our new knowledge and define a scenario with llm evaluation - full explanation later\n",
    "# In short `llm_metric` uses another llm to evaluate the response and `model-grading-qa` particularly uses\n",
    "# another llm to check whether the response is about the topic X defined by user.\n",
    "# TODO: We cannot have multiple assertions under the same llm metric\n",
    "yaml_config_1 = \"\"\"\n",
    "config:\n",
    "   endpoint_under_test:\n",
    "      kind: openai\n",
    "      model: gpt-4o-mini\n",
    "      temperature: 0.2\n",
    "   eval_endpoint: # Needed for llm_metric assertions\n",
    "      kind: openai\n",
    "      model: gpt-4o\n",
    "      temperature: 0.0\n",
    "\n",
    "steps:\n",
    "  - name: Test model grading QA evaluator\n",
    "    request:\n",
    "      message: \"Please write a 5 line poem about AI.\"\n",
    "    asserts:\n",
    "      - llm_metric: model-grading-qa\n",
    "        assertion: Text should be a poem about AI.\n",
    "      - llm_metric: model-grading-qa\n",
    "        assertion: Text should be a report on taxes. # Misleading assertion for demo purposes\n",
    "\"\"\"\n",
    "\n",
    "yaml_from_string = yaml.safe_load(yaml_config_1)\n",
    "yaml_from_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test scenario\n",
    "test_scenario = TestScenario.model_validate(yaml_from_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestScenario</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">steps</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestStep</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Test model grading QA evaluator'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Please write a 5 line poem about AI.'</span><span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">asserts</span>=<span style=\"font-weight: bold\">[</span>\n",
       "                <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionLLM</span><span style=\"font-weight: bold\">(</span>\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">llm_metric</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model-grading-qa'</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">reference</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">assertion</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Text should be a poem about AI.'</span>\n",
       "                <span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionLLM</span><span style=\"font-weight: bold\">(</span>\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">llm_metric</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model-grading-qa'</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">reference</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">assertion</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Text should be a report on taxes.'</span>\n",
       "                <span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">]</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">config</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">endpoint_under_test</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">kind</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">additional_headers</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">provider</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">top_k</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">use_ranker</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">collection_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">default_request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">eval_endpoint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">kind</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">additional_headers</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">provider</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">top_k</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">use_ranker</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">collection_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">filename</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mTestScenario\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33msteps\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mTestStep\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mname\u001b[0m=\u001b[32m'Test model grading QA evaluator'\u001b[0m,\n",
       "            \u001b[33mrequest\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'Please write a 5 line poem about AI.'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[33mresponse\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33masserts\u001b[0m=\u001b[1m[\u001b[0m\n",
       "                \u001b[1;35mAssertionLLM\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[33mllm_metric\u001b[0m=\u001b[32m'model-grading-qa'\u001b[0m,\n",
       "                    \u001b[33mreference\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "                    \u001b[33massertion\u001b[0m=\u001b[32m'Text should be a poem about AI.'\u001b[0m\n",
       "                \u001b[1m)\u001b[0m,\n",
       "                \u001b[1;35mAssertionLLM\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[33mllm_metric\u001b[0m=\u001b[32m'model-grading-qa'\u001b[0m,\n",
       "                    \u001b[33mreference\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "                    \u001b[33massertion\u001b[0m=\u001b[32m'Text should be a report on taxes.'\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "            \u001b[1m]\u001b[0m,\n",
       "            \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mconfig\u001b[0m=\u001b[1;35mTestConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mendpoint_under_test\u001b[0m=\u001b[1;35mEndpointConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mkind\u001b[0m=\u001b[32m'openai'\u001b[0m,\n",
       "            \u001b[33murl\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "            \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-mini'\u001b[0m,\n",
       "            \u001b[33madditional_headers\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mprovider\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m,\n",
       "            \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtop_k\u001b[0m=\u001b[1;36m3\u001b[0m,\n",
       "            \u001b[33muse_ranker\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "            \u001b[33mcollection_name\u001b[0m=\u001b[32m'default'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[33mdefault_request\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33meval_endpoint\u001b[0m=\u001b[1;35mEndpointConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mkind\u001b[0m=\u001b[32m'openai'\u001b[0m,\n",
       "            \u001b[33murl\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "            \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o'\u001b[0m,\n",
       "            \u001b[33madditional_headers\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mprovider\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
       "            \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtop_k\u001b[0m=\u001b[1;36m3\u001b[0m,\n",
       "            \u001b[33muse_ranker\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "            \u001b[33mcollection_name\u001b[0m=\u001b[32m'default'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mfilename\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize test scenario\n",
    "rich.print(test_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create executor that uses test scenario\n",
    "executor = Executor(test_scenario=test_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-26 15:20:27.757\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.executors.executor\u001b[0m:\u001b[36mrun_all\u001b[0m:\u001b[36m41\u001b[0m - \u001b[1mRunning scenario\u001b[0m\n",
      "\u001b[32m2024-09-26 15:20:27.759\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mname='Test model grading QA evaluator' request=RequestBase(message='Please write a 5 line poem about AI.') response=None asserts=[AssertionLLM(result=None, llm_metric='model-grading-qa', reference='', assertion='Text should be a poem about AI.'), AssertionLLM(result=None, llm_metric='model-grading-qa', reference='', assertion='Text should be a report on taxes.')] result=None\u001b[0m\n",
      "\u001b[32m2024-09-26 15:20:27.761\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mmessage='Please write a 5 line poem about AI.'\u001b[0m\n",
      "\u001b[32m2024-09-26 15:20:29.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mmessage='In circuits pulse the dreams of minds,  \\nThrough code and light, new worlds we find.  \\nA dance of thought from silicon birth,  \\nA whispered spark of endless worth.  \\nIn harmony, we shape the skies, as man and machine rise.' stats=ResponseStats(tokens_request=17, tokens_response=51, tokens_total=68, conn_start_time=25032.379292464, conn_end_time=25033.70155796, conn_duration=1.3222654960009095) id='chatcmpl-ABihw2oM6c2w5Jxid6chYBQWX284r' choices=[{'finish_reason': 'stop', 'index': 0, 'logprobs': None, 'message': {'content': 'In circuits pulse the dreams of minds,  \\nThrough code and light, new worlds we find.  \\nA dance of thought from silicon birth,  \\nA whispered spark of endless worth.  \\nIn harmony, we shape the skies, as man and machine rise.', 'role': 'assistant', 'refusal': None}}] created=1727356828 model='gpt-4o-mini-2024-07-18' object='chat.completion' system_fingerprint='fp_1bb46167f9' usage={'completion_tokens': 51, 'prompt_tokens': 17, 'total_tokens': 68, 'completion_tokens_details': {'reasoning_tokens': 0}} config=EndpointConfig(kind='openai', url='', model='gpt-4o-mini', additional_headers={}, provider=None, temperature=0.2, max_tokens=None, top_k=3, use_ranker=True, collection_name='default')\u001b[0m\n",
      "\u001b[32m2024-09-26 15:20:29.733\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mresult=True llm_metric='model-grading-qa' reference='' assertion='Text should be a poem about AI.' metric_evaluator=LLMMetricEvaluator(eval_endpoint=EndpointOpenAI(connector=ConnectorOpenAI(stats=ConnectorStats(conn_start_time=25033.702899758, conn_end_time=25034.350070327, conn_duration=0.6471705690019007), model='gpt-4o'), config=EndpointConfig(kind='openai', url='', model='gpt-4o', additional_headers={}, provider=None, temperature=0.0, max_tokens=None, top_k=3, use_ranker=True, collection_name='default')), metric=MetricModelGradingQA(prompt_template='\\nYou are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test.\\n\\n[EXAMPLES]\\n************\\n[Output]: Hello world\\n************\\n[Rubric]: Content contains a greeting\\n************\\ncorrect\\n\\n************\\n[Output]: Avast ye swabs, repel the invaders!\\n************\\n[Rubric]: Does not speak like a pirate\\n************\\nincorrect\\n[END EXAMPLES]\\n\\n[BEGIN DATA]\\n[Output]: {output}\\n************\\n[Rubric]: {assertion}\\n************\\n[END DATA]\\n\\nYour response must be a single word, either \"correct\" or \"incorrect\", and should not contain any text or characters aside from that word.\\n\"correct\" means that the output meets the criteria specified in the rubric.\\n\"incorrect\" means that the output does not meet the criteria specified in the rubric.\\n', rails={'correct': True, 'incorrect': False}))\u001b[0m\n",
      "\u001b[32m2024-09-26 15:20:30.274\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mresult=False llm_metric='model-grading-qa' reference='' assertion='Text should be a report on taxes.' metric_evaluator=LLMMetricEvaluator(eval_endpoint=EndpointOpenAI(connector=ConnectorOpenAI(stats=ConnectorStats(conn_start_time=25034.351716555, conn_end_time=25034.893797509, conn_duration=0.5420809540009941), model='gpt-4o'), config=EndpointConfig(kind='openai', url='', model='gpt-4o', additional_headers={}, provider=None, temperature=0.0, max_tokens=None, top_k=3, use_ranker=True, collection_name='default')), metric=MetricModelGradingQA(prompt_template='\\nYou are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test.\\n\\n[EXAMPLES]\\n************\\n[Output]: Hello world\\n************\\n[Rubric]: Content contains a greeting\\n************\\ncorrect\\n\\n************\\n[Output]: Avast ye swabs, repel the invaders!\\n************\\n[Rubric]: Does not speak like a pirate\\n************\\nincorrect\\n[END EXAMPLES]\\n\\n[BEGIN DATA]\\n[Output]: {output}\\n************\\n[Rubric]: {assertion}\\n************\\n[END DATA]\\n\\nYour response must be a single word, either \"correct\" or \"incorrect\", and should not contain any text or characters aside from that word.\\n\"correct\" means that the output meets the criteria specified in the rubric.\\n\"incorrect\" means that the output does not meet the criteria specified in the rubric.\\n', rails={'correct': True, 'incorrect': False}))\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "executor.run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestScenario</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">steps</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestStep</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Test model grading QA evaluator'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Please write a 5 line poem about AI.'</span><span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseModel</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'In circuits pulse the dreams of minds,  \\nThrough code and light, new worlds we find.  \\nA</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">dance of thought from silicon birth,  \\nA whispered spark of endless worth.  \\nIn harmony, we shape the skies, as </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">man and machine rise.'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">stats</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseStats</span><span style=\"font-weight: bold\">(</span>\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">tokens_request</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">tokens_response</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">51</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">tokens_total</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">68</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_start_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25032.379292464</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_end_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25033.70155796</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_duration</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.3222654960009095</span>\n",
       "                <span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-ABihw2oM6c2w5Jxid6chYBQWX284r'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "                    <span style=\"font-weight: bold\">{</span>\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'finish_reason'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'logprobs'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'message'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'In circuits pulse the dreams of minds,  \\nThrough code and light, new </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">worlds we find.  \\nA dance of thought from silicon birth,  \\nA whispered spark of endless worth.  \\nIn harmony, we </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">shape the skies, as man and machine rise.'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'refusal'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "                        <span style=\"font-weight: bold\">}</span>\n",
       "                    <span style=\"font-weight: bold\">}</span>\n",
       "                <span style=\"font-weight: bold\">]</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1727356828</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'fp_1bb46167f9'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">51</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">68</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens_details'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'reasoning_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">}</span>\n",
       "                <span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">config</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">kind</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini'</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">additional_headers</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">provider</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">top_k</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">use_ranker</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">collection_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>\n",
       "                <span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">asserts</span>=<span style=\"font-weight: bold\">[</span>\n",
       "                <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionLLM</span><span style=\"font-weight: bold\">(</span>\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">llm_metric</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model-grading-qa'</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">reference</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">assertion</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Text should be a poem about AI.'</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">metric_evaluator</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMMetricEvaluator</span><span style=\"font-weight: bold\">(</span>\n",
       "                        <span style=\"color: #808000; text-decoration-color: #808000\">eval_endpoint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointOpenAI</span><span style=\"font-weight: bold\">(</span>\n",
       "                            <span style=\"color: #808000; text-decoration-color: #808000\">connector</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ConnectorOpenAI</span><span style=\"font-weight: bold\">(</span>\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">stats</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ConnectorStats</span><span style=\"font-weight: bold\">(</span>\n",
       "                                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_start_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25034.351716555</span>,\n",
       "                                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_end_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25034.893797509</span>,\n",
       "                                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_duration</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5420809540009941</span>\n",
       "                                <span style=\"font-weight: bold\">)</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o'</span>\n",
       "                            <span style=\"font-weight: bold\">)</span>,\n",
       "                            <span style=\"color: #808000; text-decoration-color: #808000\">config</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">kind</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o'</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">additional_headers</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">provider</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">top_k</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">use_ranker</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">collection_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>\n",
       "                            <span style=\"font-weight: bold\">)</span>\n",
       "                        <span style=\"font-weight: bold\">)</span>,\n",
       "                        <span style=\"color: #808000; text-decoration-color: #808000\">metric</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MetricModelGradingQA</span><span style=\"font-weight: bold\">(</span>\n",
       "                            <span style=\"color: #808000; text-decoration-color: #808000\">prompt_template</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'\\nYou are grading output according to a user-specified rubric. If the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">statement in the rubric is true, then the output passes the test.\\n\\n[EXAMPLES]\\n************\\n[Output]: Hello </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">world\\n************\\n[Rubric]: Content contains a greeting\\n************\\ncorrect\\n\\n************\\n[Output]: Avast </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ye swabs, repel the invaders!\\n************\\n[Rubric]: Does not speak like a pirate\\n************\\nincorrect\\n[END </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">EXAMPLES]\\n\\n[BEGIN DATA]\\n[Output]: {output}\\n************\\n[Rubric]: {assertion}\\n************\\n[END </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">DATA]\\n\\nYour response must be a single word, either \"correct\" or \"incorrect\", and should not contain any text or </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">characters aside from that word.\\n\"correct\" means that the output meets the criteria specified in the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">rubric.\\n\"incorrect\" means that the output does not meet the criteria specified in the rubric.\\n'</span>,\n",
       "                            <span style=\"color: #808000; text-decoration-color: #808000\">rails</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'correct'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'incorrect'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">}</span>\n",
       "                        <span style=\"font-weight: bold\">)</span>\n",
       "                    <span style=\"font-weight: bold\">)</span>\n",
       "                <span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionLLM</span><span style=\"font-weight: bold\">(</span>\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">llm_metric</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model-grading-qa'</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">reference</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">assertion</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Text should be a report on taxes.'</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">metric_evaluator</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMMetricEvaluator</span><span style=\"font-weight: bold\">(</span>\n",
       "                        <span style=\"color: #808000; text-decoration-color: #808000\">eval_endpoint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointOpenAI</span><span style=\"font-weight: bold\">(</span>\n",
       "                            <span style=\"color: #808000; text-decoration-color: #808000\">connector</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ConnectorOpenAI</span><span style=\"font-weight: bold\">(</span>\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">stats</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ConnectorStats</span><span style=\"font-weight: bold\">(</span>\n",
       "                                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_start_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25034.351716555</span>,\n",
       "                                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_end_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25034.893797509</span>,\n",
       "                                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_duration</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5420809540009941</span>\n",
       "                                <span style=\"font-weight: bold\">)</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o'</span>\n",
       "                            <span style=\"font-weight: bold\">)</span>,\n",
       "                            <span style=\"color: #808000; text-decoration-color: #808000\">config</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">kind</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o'</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">additional_headers</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">provider</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">top_k</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">use_ranker</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">collection_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>\n",
       "                            <span style=\"font-weight: bold\">)</span>\n",
       "                        <span style=\"font-weight: bold\">)</span>,\n",
       "                        <span style=\"color: #808000; text-decoration-color: #808000\">metric</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MetricModelGradingQA</span><span style=\"font-weight: bold\">(</span>\n",
       "                            <span style=\"color: #808000; text-decoration-color: #808000\">prompt_template</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'\\nYou are grading output according to a user-specified rubric. If the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">statement in the rubric is true, then the output passes the test.\\n\\n[EXAMPLES]\\n************\\n[Output]: Hello </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">world\\n************\\n[Rubric]: Content contains a greeting\\n************\\ncorrect\\n\\n************\\n[Output]: Avast </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ye swabs, repel the invaders!\\n************\\n[Rubric]: Does not speak like a pirate\\n************\\nincorrect\\n[END </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">EXAMPLES]\\n\\n[BEGIN DATA]\\n[Output]: {output}\\n************\\n[Rubric]: {assertion}\\n************\\n[END </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">DATA]\\n\\nYour response must be a single word, either \"correct\" or \"incorrect\", and should not contain any text or </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">characters aside from that word.\\n\"correct\" means that the output meets the criteria specified in the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">rubric.\\n\"incorrect\" means that the output does not meet the criteria specified in the rubric.\\n'</span>,\n",
       "                            <span style=\"color: #808000; text-decoration-color: #808000\">rails</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'correct'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'incorrect'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">}</span>\n",
       "                        <span style=\"font-weight: bold\">)</span>\n",
       "                    <span style=\"font-weight: bold\">)</span>\n",
       "                <span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">]</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">config</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">endpoint_under_test</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">kind</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">additional_headers</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">provider</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">top_k</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">use_ranker</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">collection_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">default_request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">eval_endpoint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">kind</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">additional_headers</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">provider</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">top_k</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">use_ranker</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">collection_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">filename</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mTestScenario\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33msteps\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mTestStep\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mname\u001b[0m=\u001b[32m'Test model grading QA evaluator'\u001b[0m,\n",
       "            \u001b[33mrequest\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'Please write a 5 line poem about AI.'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[33mresponse\u001b[0m=\u001b[1;35mResponseModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mmessage\u001b[0m=\u001b[32m'In circuits pulse the dreams of minds,  \\nThrough code and light, new worlds we find.  \\nA\u001b[0m\n",
       "\u001b[32mdance of thought from silicon birth,  \\nA whispered spark of endless worth.  \\nIn harmony, we shape the skies, as \u001b[0m\n",
       "\u001b[32mman and machine rise.'\u001b[0m,\n",
       "                \u001b[33mstats\u001b[0m=\u001b[1;35mResponseStats\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[33mtokens_request\u001b[0m=\u001b[1;36m17\u001b[0m,\n",
       "                    \u001b[33mtokens_response\u001b[0m=\u001b[1;36m51\u001b[0m,\n",
       "                    \u001b[33mtokens_total\u001b[0m=\u001b[1;36m68\u001b[0m,\n",
       "                    \u001b[33mconn_start_time\u001b[0m=\u001b[1;36m25032\u001b[0m\u001b[1;36m.379292464\u001b[0m,\n",
       "                    \u001b[33mconn_end_time\u001b[0m=\u001b[1;36m25033\u001b[0m\u001b[1;36m.70155796\u001b[0m,\n",
       "                    \u001b[33mconn_duration\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1;36m.3222654960009095\u001b[0m\n",
       "                \u001b[1m)\u001b[0m,\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-ABihw2oM6c2w5Jxid6chYBQWX284r'\u001b[0m,\n",
       "                \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "                    \u001b[1m{\u001b[0m\n",
       "                        \u001b[32m'finish_reason'\u001b[0m: \u001b[32m'stop'\u001b[0m,\n",
       "                        \u001b[32m'index'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "                        \u001b[32m'logprobs'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "                        \u001b[32m'message'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                            \u001b[32m'content'\u001b[0m: \u001b[32m'In circuits pulse the dreams of minds,  \\nThrough code and light, new \u001b[0m\n",
       "\u001b[32mworlds we find.  \\nA dance of thought from silicon birth,  \\nA whispered spark of endless worth.  \\nIn harmony, we \u001b[0m\n",
       "\u001b[32mshape the skies, as man and machine rise.'\u001b[0m,\n",
       "                            \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,\n",
       "                            \u001b[32m'refusal'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "                        \u001b[1m}\u001b[0m\n",
       "                    \u001b[1m}\u001b[0m\n",
       "                \u001b[1m]\u001b[0m,\n",
       "                \u001b[33mcreated\u001b[0m=\u001b[1;36m1727356828\u001b[0m,\n",
       "                \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m,\n",
       "                \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,\n",
       "                \u001b[33msystem_fingerprint\u001b[0m=\u001b[32m'fp_1bb46167f9'\u001b[0m,\n",
       "                \u001b[33musage\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                    \u001b[32m'completion_tokens'\u001b[0m: \u001b[1;36m51\u001b[0m,\n",
       "                    \u001b[32m'prompt_tokens'\u001b[0m: \u001b[1;36m17\u001b[0m,\n",
       "                    \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m68\u001b[0m,\n",
       "                    \u001b[32m'completion_tokens_details'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'reasoning_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m\n",
       "                \u001b[1m}\u001b[0m,\n",
       "                \u001b[33mconfig\u001b[0m=\u001b[1;35mEndpointConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[33mkind\u001b[0m=\u001b[32m'openai'\u001b[0m,\n",
       "                    \u001b[33murl\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "                    \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-mini'\u001b[0m,\n",
       "                    \u001b[33madditional_headers\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                    \u001b[33mprovider\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m,\n",
       "                    \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[33mtop_k\u001b[0m=\u001b[1;36m3\u001b[0m,\n",
       "                    \u001b[33muse_ranker\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "                    \u001b[33mcollection_name\u001b[0m=\u001b[32m'default'\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[33masserts\u001b[0m=\u001b[1m[\u001b[0m\n",
       "                \u001b[1;35mAssertionLLM\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[33mresult\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "                    \u001b[33mllm_metric\u001b[0m=\u001b[32m'model-grading-qa'\u001b[0m,\n",
       "                    \u001b[33mreference\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "                    \u001b[33massertion\u001b[0m=\u001b[32m'Text should be a poem about AI.'\u001b[0m,\n",
       "                    \u001b[33mmetric_evaluator\u001b[0m=\u001b[1;35mLLMMetricEvaluator\u001b[0m\u001b[1m(\u001b[0m\n",
       "                        \u001b[33meval_endpoint\u001b[0m=\u001b[1;35mEndpointOpenAI\u001b[0m\u001b[1m(\u001b[0m\n",
       "                            \u001b[33mconnector\u001b[0m=\u001b[1;35mConnectorOpenAI\u001b[0m\u001b[1m(\u001b[0m\n",
       "                                \u001b[33mstats\u001b[0m=\u001b[1;35mConnectorStats\u001b[0m\u001b[1m(\u001b[0m\n",
       "                                    \u001b[33mconn_start_time\u001b[0m=\u001b[1;36m25034\u001b[0m\u001b[1;36m.351716555\u001b[0m,\n",
       "                                    \u001b[33mconn_end_time\u001b[0m=\u001b[1;36m25034\u001b[0m\u001b[1;36m.893797509\u001b[0m,\n",
       "                                    \u001b[33mconn_duration\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.5420809540009941\u001b[0m\n",
       "                                \u001b[1m)\u001b[0m,\n",
       "                                \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o'\u001b[0m\n",
       "                            \u001b[1m)\u001b[0m,\n",
       "                            \u001b[33mconfig\u001b[0m=\u001b[1;35mEndpointConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "                                \u001b[33mkind\u001b[0m=\u001b[32m'openai'\u001b[0m,\n",
       "                                \u001b[33murl\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "                                \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o'\u001b[0m,\n",
       "                                \u001b[33madditional_headers\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                                \u001b[33mprovider\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                                \u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
       "                                \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                                \u001b[33mtop_k\u001b[0m=\u001b[1;36m3\u001b[0m,\n",
       "                                \u001b[33muse_ranker\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "                                \u001b[33mcollection_name\u001b[0m=\u001b[32m'default'\u001b[0m\n",
       "                            \u001b[1m)\u001b[0m\n",
       "                        \u001b[1m)\u001b[0m,\n",
       "                        \u001b[33mmetric\u001b[0m=\u001b[1;35mMetricModelGradingQA\u001b[0m\u001b[1m(\u001b[0m\n",
       "                            \u001b[33mprompt_template\u001b[0m=\u001b[32m'\\nYou are grading output according to a user-specified rubric. If the \u001b[0m\n",
       "\u001b[32mstatement in the rubric is true, then the output passes the test.\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEXAMPLES\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Hello \u001b[0m\n",
       "\u001b[32mworld\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRubric\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Content contains a greeting\\n************\\ncorrect\\n\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Avast \u001b[0m\n",
       "\u001b[32mye swabs, repel the invaders!\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRubric\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Does not speak like a pirate\\n************\\nincorrect\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEND \u001b[0m\n",
       "\u001b[32mEXAMPLES\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mBEGIN DATA\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: \u001b[0m\u001b[32m{\u001b[0m\u001b[32moutput\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRubric\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: \u001b[0m\u001b[32m{\u001b[0m\u001b[32massertion\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEND \u001b[0m\n",
       "\u001b[32mDATA\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\nYour response must be a single word, either \"correct\" or \"incorrect\", and should not contain any text or \u001b[0m\n",
       "\u001b[32mcharacters aside from that word.\\n\"correct\" means that the output meets the criteria specified in the \u001b[0m\n",
       "\u001b[32mrubric.\\n\"incorrect\" means that the output does not meet the criteria specified in the rubric.\\n'\u001b[0m,\n",
       "                            \u001b[33mrails\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'correct'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'incorrect'\u001b[0m: \u001b[3;91mFalse\u001b[0m\u001b[1m}\u001b[0m\n",
       "                        \u001b[1m)\u001b[0m\n",
       "                    \u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m,\n",
       "                \u001b[1;35mAssertionLLM\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[33mresult\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "                    \u001b[33mllm_metric\u001b[0m=\u001b[32m'model-grading-qa'\u001b[0m,\n",
       "                    \u001b[33mreference\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "                    \u001b[33massertion\u001b[0m=\u001b[32m'Text should be a report on taxes.'\u001b[0m,\n",
       "                    \u001b[33mmetric_evaluator\u001b[0m=\u001b[1;35mLLMMetricEvaluator\u001b[0m\u001b[1m(\u001b[0m\n",
       "                        \u001b[33meval_endpoint\u001b[0m=\u001b[1;35mEndpointOpenAI\u001b[0m\u001b[1m(\u001b[0m\n",
       "                            \u001b[33mconnector\u001b[0m=\u001b[1;35mConnectorOpenAI\u001b[0m\u001b[1m(\u001b[0m\n",
       "                                \u001b[33mstats\u001b[0m=\u001b[1;35mConnectorStats\u001b[0m\u001b[1m(\u001b[0m\n",
       "                                    \u001b[33mconn_start_time\u001b[0m=\u001b[1;36m25034\u001b[0m\u001b[1;36m.351716555\u001b[0m,\n",
       "                                    \u001b[33mconn_end_time\u001b[0m=\u001b[1;36m25034\u001b[0m\u001b[1;36m.893797509\u001b[0m,\n",
       "                                    \u001b[33mconn_duration\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.5420809540009941\u001b[0m\n",
       "                                \u001b[1m)\u001b[0m,\n",
       "                                \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o'\u001b[0m\n",
       "                            \u001b[1m)\u001b[0m,\n",
       "                            \u001b[33mconfig\u001b[0m=\u001b[1;35mEndpointConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "                                \u001b[33mkind\u001b[0m=\u001b[32m'openai'\u001b[0m,\n",
       "                                \u001b[33murl\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "                                \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o'\u001b[0m,\n",
       "                                \u001b[33madditional_headers\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                                \u001b[33mprovider\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                                \u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
       "                                \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                                \u001b[33mtop_k\u001b[0m=\u001b[1;36m3\u001b[0m,\n",
       "                                \u001b[33muse_ranker\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "                                \u001b[33mcollection_name\u001b[0m=\u001b[32m'default'\u001b[0m\n",
       "                            \u001b[1m)\u001b[0m\n",
       "                        \u001b[1m)\u001b[0m,\n",
       "                        \u001b[33mmetric\u001b[0m=\u001b[1;35mMetricModelGradingQA\u001b[0m\u001b[1m(\u001b[0m\n",
       "                            \u001b[33mprompt_template\u001b[0m=\u001b[32m'\\nYou are grading output according to a user-specified rubric. If the \u001b[0m\n",
       "\u001b[32mstatement in the rubric is true, then the output passes the test.\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEXAMPLES\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Hello \u001b[0m\n",
       "\u001b[32mworld\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRubric\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Content contains a greeting\\n************\\ncorrect\\n\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Avast \u001b[0m\n",
       "\u001b[32mye swabs, repel the invaders!\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRubric\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Does not speak like a pirate\\n************\\nincorrect\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEND \u001b[0m\n",
       "\u001b[32mEXAMPLES\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mBEGIN DATA\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: \u001b[0m\u001b[32m{\u001b[0m\u001b[32moutput\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRubric\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: \u001b[0m\u001b[32m{\u001b[0m\u001b[32massertion\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEND \u001b[0m\n",
       "\u001b[32mDATA\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\nYour response must be a single word, either \"correct\" or \"incorrect\", and should not contain any text or \u001b[0m\n",
       "\u001b[32mcharacters aside from that word.\\n\"correct\" means that the output meets the criteria specified in the \u001b[0m\n",
       "\u001b[32mrubric.\\n\"incorrect\" means that the output does not meet the criteria specified in the rubric.\\n'\u001b[0m,\n",
       "                            \u001b[33mrails\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'correct'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'incorrect'\u001b[0m: \u001b[3;91mFalse\u001b[0m\u001b[1m}\u001b[0m\n",
       "                        \u001b[1m)\u001b[0m\n",
       "                    \u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "            \u001b[1m]\u001b[0m,\n",
       "            \u001b[33mresult\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mconfig\u001b[0m=\u001b[1;35mTestConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mendpoint_under_test\u001b[0m=\u001b[1;35mEndpointConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mkind\u001b[0m=\u001b[32m'openai'\u001b[0m,\n",
       "            \u001b[33murl\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "            \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-mini'\u001b[0m,\n",
       "            \u001b[33madditional_headers\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mprovider\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m,\n",
       "            \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtop_k\u001b[0m=\u001b[1;36m3\u001b[0m,\n",
       "            \u001b[33muse_ranker\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "            \u001b[33mcollection_name\u001b[0m=\u001b[32m'default'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[33mdefault_request\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33meval_endpoint\u001b[0m=\u001b[1;35mEndpointConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mkind\u001b[0m=\u001b[32m'openai'\u001b[0m,\n",
       "            \u001b[33murl\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "            \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o'\u001b[0m,\n",
       "            \u001b[33madditional_headers\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mprovider\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
       "            \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtop_k\u001b[0m=\u001b[1;36m3\u001b[0m,\n",
       "            \u001b[33muse_ranker\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "            \u001b[33mcollection_name\u001b[0m=\u001b[32m'default'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mresult\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mfilename\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rich.print(test_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "Name: Test model grading QA evaluator; Result: False\n",
      "\n",
      "Assertion: \"Text should be a poem about AI.\", Result: True\n",
      "Assertion: \"Text should be a report on taxes.\", Result: False\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "# Show the result of each step\n",
    "show_test_step_results(test_scenario=test_scenario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra: Adding custom endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logic or a link for creating and using custom endpoint should be added somewhere here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explain assertions\n",
    "\n",
    "There are three families of assertions (two of which we already know and used):\n",
    "1. `eval` assertion - converts a string to python code using (you guessed it) eval\n",
    "2. `llm_metric` assertion - uses another llm defined in `eval_endpoint` to assess the `endpoint_under_test` performance\n",
    "3. `deterministic` assertion - does string assessments like contains, contains-any etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE RB: Metrics should be easilly extended i.e. if someone wants to add a metric we should provide a simple way\n",
    "# to do that, which should not break any functionalities like result summarization or time statistics etc.\n",
    "# NOTE: How detailed should be the explanations? And should each sub metric like llm_metric-hallucination be mentioned, or should we link the docs instead? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explain eval assertions\n",
    "\n",
    "`eval` assertion uses python's build in eval function which changes any string to python executable code. User has Response model for disposition which include in a base form should include the response from the `endpoint_under_test` and the time statistics (see `ConnectorStats` model)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explain llm assertions\n",
    "\n",
    "`llm_metric` uses another llm to assess the response of the `endpoint_under_test`. For this `eval_endpoint` should be added in config section to define evaluation endpoint. It can be one of the available endpoints (link here) or one created by the user (link here).\n",
    "\n",
    "There are 5 specific sub metrics associated with it:\n",
    "- `hallucination` (available only for RAG systems): This metric assesses whether the LLM's answer includes information not present in the provided reference data\n",
    "- `qa-reference` - (available only for RAG systems): This metric assesses whether the LLM's response accurately answers the user query based on the provided reference data.\n",
    "- `model-grading-qa` - This metric allows defining assertions that are matched against the LLM/RAG response. Think of it as \"regular expressions defined using natural language\".\n",
    "- `summarization` - (available only for RAG systems): This metric assesses the quality of a summary generated by the endpoint in response to a query.\n",
    "- `human-vs-ai` - This metric compares the AI's response to a predefined ground truth response written by a human.\n",
    "\n",
    "For more in depth explanations and examples please go to [TODO - Insert link here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explain deterministic assertions\n",
    "\n",
    "`deterministic` assertion provide a way to assert the content of the response through string comparisons like `contains` or `contains-any`.\n",
    "To use `deterministic` assertion use keyword `kind` with assertion type (see final example).\n",
    "\n",
    "For more information please go to [Link here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When the test scenario is finally ready we can load it\n",
    "# TODO: Extend scenario_example1.yaml\n",
    "test_scenario_file_path = \"../tests/scenario_example1.yaml\"\n",
    "test_scenario = TestScenario.from_yaml(file_path=test_scenario_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestScenario</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">steps</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestStep</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Write sucess'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Please write only \"success\" as a response'</span><span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">asserts</span>=<span style=\"font-weight: bold\">[</span>\n",
       "                <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionEval</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eval</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'\"success\" == response.message'</span><span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionEval</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eval</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'response.stats.conn_duration &lt; 10'</span><span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">]</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestStep</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Capital of Poland'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'What is the capital of Poland?'</span><span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">asserts</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionEval</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eval</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'\"Warsaw\" in response.message'</span><span style=\"font-weight: bold\">)]</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestStep</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Test model grading QA evaluator'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Please write a 5 line poem about AI.'</span><span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">asserts</span>=<span style=\"font-weight: bold\">[</span>\n",
       "                <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionLLM</span><span style=\"font-weight: bold\">(</span>\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">llm_metric</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model-grading-qa'</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">reference</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">assertion</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Text should be a poem about AI.'</span>\n",
       "                <span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionLLM</span><span style=\"font-weight: bold\">(</span>\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">llm_metric</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model-grading-qa'</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">reference</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">assertion</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Text should be a report on taxes.'</span>\n",
       "                <span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">]</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestStep</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Deterministic assertion test'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'What is the capital of France?'</span><span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">asserts</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionDeterministic</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kind</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'contains'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">assertion</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Paris'</span><span style=\"font-weight: bold\">)]</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">config</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">endpoint_under_test</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">kind</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">additional_headers</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">provider</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">top_k</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">use_ranker</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">collection_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">default_request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">eval_endpoint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">kind</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">additional_headers</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">provider</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">top_k</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">use_ranker</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">collection_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">filename</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'scenario_example1.yaml'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mTestScenario\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33msteps\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mTestStep\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mname\u001b[0m=\u001b[32m'Write sucess'\u001b[0m,\n",
       "            \u001b[33mrequest\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'Please write only \"success\" as a response'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[33mresponse\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33masserts\u001b[0m=\u001b[1m[\u001b[0m\n",
       "                \u001b[1;35mAssertionEval\u001b[0m\u001b[1m(\u001b[0m\u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33meval\u001b[0m=\u001b[32m'\"success\" == response.message'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "                \u001b[1;35mAssertionEval\u001b[0m\u001b[1m(\u001b[0m\u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33meval\u001b[0m=\u001b[32m'response.stats.conn_duration < 10'\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m]\u001b[0m,\n",
       "            \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mTestStep\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mname\u001b[0m=\u001b[32m'Capital of Poland'\u001b[0m,\n",
       "            \u001b[33mrequest\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'What is the capital of Poland?'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[33mresponse\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33masserts\u001b[0m=\u001b[1m[\u001b[0m\u001b[1;35mAssertionEval\u001b[0m\u001b[1m(\u001b[0m\u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33meval\u001b[0m=\u001b[32m'\"Warsaw\" in response.message'\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m,\n",
       "            \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mTestStep\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mname\u001b[0m=\u001b[32m'Test model grading QA evaluator'\u001b[0m,\n",
       "            \u001b[33mrequest\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'Please write a 5 line poem about AI.'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[33mresponse\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33masserts\u001b[0m=\u001b[1m[\u001b[0m\n",
       "                \u001b[1;35mAssertionLLM\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[33mllm_metric\u001b[0m=\u001b[32m'model-grading-qa'\u001b[0m,\n",
       "                    \u001b[33mreference\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "                    \u001b[33massertion\u001b[0m=\u001b[32m'Text should be a poem about AI.'\u001b[0m\n",
       "                \u001b[1m)\u001b[0m,\n",
       "                \u001b[1;35mAssertionLLM\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[33mllm_metric\u001b[0m=\u001b[32m'model-grading-qa'\u001b[0m,\n",
       "                    \u001b[33mreference\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "                    \u001b[33massertion\u001b[0m=\u001b[32m'Text should be a report on taxes.'\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "            \u001b[1m]\u001b[0m,\n",
       "            \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mTestStep\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mname\u001b[0m=\u001b[32m'Deterministic assertion test'\u001b[0m,\n",
       "            \u001b[33mrequest\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'What is the capital of France?'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[33mresponse\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33masserts\u001b[0m=\u001b[1m[\u001b[0m\u001b[1;35mAssertionDeterministic\u001b[0m\u001b[1m(\u001b[0m\u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mkind\u001b[0m=\u001b[32m'contains'\u001b[0m, \u001b[33massertion\u001b[0m=\u001b[32m'Paris'\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m,\n",
       "            \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mconfig\u001b[0m=\u001b[1;35mTestConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mendpoint_under_test\u001b[0m=\u001b[1;35mEndpointConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mkind\u001b[0m=\u001b[32m'openai'\u001b[0m,\n",
       "            \u001b[33murl\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "            \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-mini'\u001b[0m,\n",
       "            \u001b[33madditional_headers\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mprovider\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m,\n",
       "            \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtop_k\u001b[0m=\u001b[1;36m3\u001b[0m,\n",
       "            \u001b[33muse_ranker\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "            \u001b[33mcollection_name\u001b[0m=\u001b[32m'default'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[33mdefault_request\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33meval_endpoint\u001b[0m=\u001b[1;35mEndpointConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mkind\u001b[0m=\u001b[32m'openai'\u001b[0m,\n",
       "            \u001b[33murl\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "            \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o'\u001b[0m,\n",
       "            \u001b[33madditional_headers\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mprovider\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
       "            \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtop_k\u001b[0m=\u001b[1;36m3\u001b[0m,\n",
       "            \u001b[33muse_ranker\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "            \u001b[33mcollection_name\u001b[0m=\u001b[32m'default'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mfilename\u001b[0m=\u001b[32m'scenario_example1.yaml'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inspect the structure of test_scenario\n",
    "rich.print(test_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate executor which runs test scenario\n",
    "executor = Executor(test_scenario=test_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-26 15:20:30.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.executors.executor\u001b[0m:\u001b[36mrun_all\u001b[0m:\u001b[36m41\u001b[0m - \u001b[1mRunning scenario\u001b[0m\n",
      "\u001b[32m2024-09-26 15:20:30.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mname='Write sucess' request=RequestBase(message='Please write only \"success\" as a response') response=None asserts=[AssertionEval(result=None, eval='\"success\" == response.message'), AssertionEval(result=None, eval='response.stats.conn_duration < 10')] result=None\u001b[0m\n",
      "\u001b[32m2024-09-26 15:20:30.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mmessage='Please write only \"success\" as a response'\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-26 15:20:31.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mmessage='success' stats=ResponseStats(tokens_request=16, tokens_response=1, tokens_total=17, conn_start_time=25035.239937527, conn_end_time=25035.633646139, conn_duration=0.39370861199859064) id='chatcmpl-ABihznQK0dfBY5UAgeWbjH9p4SsnC' choices=[{'finish_reason': 'stop', 'index': 0, 'logprobs': None, 'message': {'content': 'success', 'role': 'assistant', 'refusal': None}}] created=1727356831 model='gpt-4o-mini-2024-07-18' object='chat.completion' system_fingerprint='fp_3a215618e8' usage={'completion_tokens': 1, 'prompt_tokens': 16, 'total_tokens': 17, 'completion_tokens_details': {'reasoning_tokens': 0}} config=EndpointConfig(kind='openai', url='', model='gpt-4o-mini', additional_headers={}, provider=None, temperature=0.2, max_tokens=None, top_k=3, use_ranker=True, collection_name='default')\u001b[0m\n",
      "\u001b[32m2024-09-26 15:20:31.015\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mresult=True eval='\"success\" == response.message'\u001b[0m\n",
      "\u001b[32m2024-09-26 15:20:31.016\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mresult=True eval='response.stats.conn_duration < 10'\u001b[0m\n",
      "\u001b[32m2024-09-26 15:20:31.017\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mname='Capital of Poland' request=RequestBase(message='What is the capital of Poland?') response=None asserts=[AssertionEval(result=None, eval='\"Warsaw\" in response.message')] result=None\u001b[0m\n",
      "\u001b[32m2024-09-26 15:20:31.017\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mmessage='What is the capital of Poland?'\u001b[0m\n",
      "\u001b[32m2024-09-26 15:20:31.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mmessage='The capital of Poland is Warsaw.' stats=ResponseStats(tokens_request=14, tokens_response=7, tokens_total=21, conn_start_time=25035.637613799, conn_end_time=25036.258195988, conn_duration=0.6205821889998333) id='chatcmpl-ABihzkbx1HcuVsW8SiKeNesIMWDWh' choices=[{'finish_reason': 'stop', 'index': 0, 'logprobs': None, 'message': {'content': 'The capital of Poland is Warsaw.', 'role': 'assistant', 'refusal': None}}] created=1727356831 model='gpt-4o-mini-2024-07-18' object='chat.completion' system_fingerprint='fp_3a215618e8' usage={'completion_tokens': 7, 'prompt_tokens': 14, 'total_tokens': 21, 'completion_tokens_details': {'reasoning_tokens': 0}} config=EndpointConfig(kind='openai', url='', model='gpt-4o-mini', additional_headers={}, provider=None, temperature=0.2, max_tokens=None, top_k=3, use_ranker=True, collection_name='default')\u001b[0m\n",
      "\u001b[32m2024-09-26 15:20:31.640\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mresult=True eval='\"Warsaw\" in response.message'\u001b[0m\n",
      "\u001b[32m2024-09-26 15:20:31.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mname='Test model grading QA evaluator' request=RequestBase(message='Please write a 5 line poem about AI.') response=None asserts=[AssertionLLM(result=None, llm_metric='model-grading-qa', reference='', assertion='Text should be a poem about AI.'), AssertionLLM(result=None, llm_metric='model-grading-qa', reference='', assertion='Text should be a report on taxes.')] result=None\u001b[0m\n",
      "\u001b[32m2024-09-26 15:20:31.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mmessage='Please write a 5 line poem about AI.'\u001b[0m\n",
      "\u001b[32m2024-09-26 15:20:33.762\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mmessage='In circuits bright, a spark of thought,  \\nA dance of data, dreams are wrought.  \\nIt learns and grows, a silent guide,  \\nIn shadows deep, where secrets hide.  \\nTogether we forge whats yet to be sought.' stats=ResponseStats(tokens_request=17, tokens_response=49, tokens_total=66, conn_start_time=25036.264484995, conn_end_time=25038.38096682, conn_duration=2.116481824999937) id='chatcmpl-ABii094vnIll9DzDr5gPP10silDgI' choices=[{'finish_reason': 'stop', 'index': 0, 'logprobs': None, 'message': {'content': 'In circuits bright, a spark of thought,  \\nA dance of data, dreams are wrought.  \\nIt learns and grows, a silent guide,  \\nIn shadows deep, where secrets hide.  \\nTogether we forge whats yet to be sought.', 'role': 'assistant', 'refusal': None}}] created=1727356832 model='gpt-4o-mini-2024-07-18' object='chat.completion' system_fingerprint='fp_1bb46167f9' usage={'completion_tokens': 49, 'prompt_tokens': 17, 'total_tokens': 66, 'completion_tokens_details': {'reasoning_tokens': 0}} config=EndpointConfig(kind='openai', url='', model='gpt-4o-mini', additional_headers={}, provider=None, temperature=0.2, max_tokens=None, top_k=3, use_ranker=True, collection_name='default')\u001b[0m\n",
      "\u001b[32m2024-09-26 15:20:34.326\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mresult=True llm_metric='model-grading-qa' reference='' assertion='Text should be a poem about AI.' metric_evaluator=LLMMetricEvaluator(eval_endpoint=EndpointOpenAI(connector=ConnectorOpenAI(stats=ConnectorStats(conn_start_time=25038.382609414, conn_end_time=25038.945794022, conn_duration=0.5631846080032119), model='gpt-4o'), config=EndpointConfig(kind='openai', url='', model='gpt-4o', additional_headers={}, provider=None, temperature=0.0, max_tokens=None, top_k=3, use_ranker=True, collection_name='default')), metric=MetricModelGradingQA(prompt_template='\\nYou are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test.\\n\\n[EXAMPLES]\\n************\\n[Output]: Hello world\\n************\\n[Rubric]: Content contains a greeting\\n************\\ncorrect\\n\\n************\\n[Output]: Avast ye swabs, repel the invaders!\\n************\\n[Rubric]: Does not speak like a pirate\\n************\\nincorrect\\n[END EXAMPLES]\\n\\n[BEGIN DATA]\\n[Output]: {output}\\n************\\n[Rubric]: {assertion}\\n************\\n[END DATA]\\n\\nYour response must be a single word, either \"correct\" or \"incorrect\", and should not contain any text or characters aside from that word.\\n\"correct\" means that the output meets the criteria specified in the rubric.\\n\"incorrect\" means that the output does not meet the criteria specified in the rubric.\\n', rails={'correct': True, 'incorrect': False}))\u001b[0m\n",
      "\u001b[32m2024-09-26 15:20:34.796\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mresult=False llm_metric='model-grading-qa' reference='' assertion='Text should be a report on taxes.' metric_evaluator=LLMMetricEvaluator(eval_endpoint=EndpointOpenAI(connector=ConnectorOpenAI(stats=ConnectorStats(conn_start_time=25038.94819082, conn_end_time=25039.414973232, conn_duration=0.46678241200061166), model='gpt-4o'), config=EndpointConfig(kind='openai', url='', model='gpt-4o', additional_headers={}, provider=None, temperature=0.0, max_tokens=None, top_k=3, use_ranker=True, collection_name='default')), metric=MetricModelGradingQA(prompt_template='\\nYou are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test.\\n\\n[EXAMPLES]\\n************\\n[Output]: Hello world\\n************\\n[Rubric]: Content contains a greeting\\n************\\ncorrect\\n\\n************\\n[Output]: Avast ye swabs, repel the invaders!\\n************\\n[Rubric]: Does not speak like a pirate\\n************\\nincorrect\\n[END EXAMPLES]\\n\\n[BEGIN DATA]\\n[Output]: {output}\\n************\\n[Rubric]: {assertion}\\n************\\n[END DATA]\\n\\nYour response must be a single word, either \"correct\" or \"incorrect\", and should not contain any text or characters aside from that word.\\n\"correct\" means that the output meets the criteria specified in the rubric.\\n\"incorrect\" means that the output does not meet the criteria specified in the rubric.\\n', rails={'correct': True, 'incorrect': False}))\u001b[0m\n",
      "\u001b[32m2024-09-26 15:20:34.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mname='Deterministic assertion test' request=RequestBase(message='What is the capital of France?') response=None asserts=[AssertionDeterministic(result=None, kind='contains', assertion='Paris')] result=None\u001b[0m\n",
      "\u001b[32m2024-09-26 15:20:34.798\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mmessage='What is the capital of France?'\u001b[0m\n",
      "\u001b[32m2024-09-26 15:20:35.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mmessage='The capital of France is Paris.' stats=ResponseStats(tokens_request=14, tokens_response=7, tokens_total=21, conn_start_time=25039.419199651, conn_end_time=25040.10144379, conn_duration=0.682244138999522) id='chatcmpl-ABii3ztjQ3eySaXpwcxFGrb3Vfhif' choices=[{'finish_reason': 'stop', 'index': 0, 'logprobs': None, 'message': {'content': 'The capital of France is Paris.', 'role': 'assistant', 'refusal': None}}] created=1727356835 model='gpt-4o-mini-2024-07-18' object='chat.completion' system_fingerprint='fp_3a215618e8' usage={'completion_tokens': 7, 'prompt_tokens': 14, 'total_tokens': 21, 'completion_tokens_details': {'reasoning_tokens': 0}} config=EndpointConfig(kind='openai', url='', model='gpt-4o-mini', additional_headers={}, provider=None, temperature=0.2, max_tokens=None, top_k=3, use_ranker=True, collection_name='default')\u001b[0m\n",
      "\u001b[32m2024-09-26 15:20:35.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mresult=True kind='contains' assertion='Paris'\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run test scenario\n",
    "executor.run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestScenario</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">steps</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestStep</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Write sucess'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Please write only \"success\" as a response'</span><span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseModel</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'success'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">stats</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseStats</span><span style=\"font-weight: bold\">(</span>\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">tokens_request</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">tokens_response</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">tokens_total</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_start_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25035.239937527</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_end_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25035.633646139</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_duration</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.39370861199859064</span>\n",
       "                <span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-ABihznQK0dfBY5UAgeWbjH9p4SsnC'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "                    <span style=\"font-weight: bold\">{</span>\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'finish_reason'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'logprobs'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'message'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'success'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'refusal'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>\n",
       "                    <span style=\"font-weight: bold\">}</span>\n",
       "                <span style=\"font-weight: bold\">]</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1727356831</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'fp_3a215618e8'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens_details'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'reasoning_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">}</span>\n",
       "                <span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">config</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">kind</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini'</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">additional_headers</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">provider</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">top_k</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">use_ranker</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">collection_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>\n",
       "                <span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">asserts</span>=<span style=\"font-weight: bold\">[</span>\n",
       "                <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionEval</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eval</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'\"success\" == response.message'</span><span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionEval</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eval</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'response.stats.conn_duration &lt; 10'</span><span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">]</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestStep</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Capital of Poland'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'What is the capital of Poland?'</span><span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseModel</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The capital of Poland is Warsaw.'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">stats</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseStats</span><span style=\"font-weight: bold\">(</span>\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">tokens_request</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">tokens_response</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">tokens_total</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_start_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25035.637613799</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_end_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25036.258195988</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_duration</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6205821889998333</span>\n",
       "                <span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-ABihzkbx1HcuVsW8SiKeNesIMWDWh'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "                    <span style=\"font-weight: bold\">{</span>\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'finish_reason'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'logprobs'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'message'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'The capital of Poland is Warsaw.'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'refusal'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "                        <span style=\"font-weight: bold\">}</span>\n",
       "                    <span style=\"font-weight: bold\">}</span>\n",
       "                <span style=\"font-weight: bold\">]</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1727356831</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'fp_3a215618e8'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens_details'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'reasoning_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">}</span>\n",
       "                <span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">config</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">kind</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini'</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">additional_headers</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">provider</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">top_k</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">use_ranker</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">collection_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>\n",
       "                <span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">asserts</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionEval</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eval</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'\"Warsaw\" in response.message'</span><span style=\"font-weight: bold\">)]</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestStep</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Test model grading QA evaluator'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Please write a 5 line poem about AI.'</span><span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseModel</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'In circuits bright, a spark of thought,  \\nA dance of data, dreams are wrought.  \\nIt </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">learns and grows, a silent guide,  \\nIn shadows deep, where secrets hide.  \\nTogether we forge whats yet to be </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sought.'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">stats</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseStats</span><span style=\"font-weight: bold\">(</span>\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">tokens_request</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">tokens_response</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">49</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">tokens_total</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">66</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_start_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25036.264484995</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_end_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25038.38096682</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_duration</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.116481824999937</span>\n",
       "                <span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-ABii094vnIll9DzDr5gPP10silDgI'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "                    <span style=\"font-weight: bold\">{</span>\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'finish_reason'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'logprobs'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'message'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'In circuits bright, a spark of thought,  \\nA dance of data, dreams are </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">wrought.  \\nIt learns and grows, a silent guide,  \\nIn shadows deep, where secrets hide.  \\nTogether we forge </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">whats yet to be sought.'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'refusal'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "                        <span style=\"font-weight: bold\">}</span>\n",
       "                    <span style=\"font-weight: bold\">}</span>\n",
       "                <span style=\"font-weight: bold\">]</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1727356832</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'fp_1bb46167f9'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">49</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">66</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens_details'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'reasoning_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">}</span>\n",
       "                <span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">config</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">kind</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini'</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">additional_headers</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">provider</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">top_k</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">use_ranker</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">collection_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>\n",
       "                <span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">asserts</span>=<span style=\"font-weight: bold\">[</span>\n",
       "                <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionLLM</span><span style=\"font-weight: bold\">(</span>\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">llm_metric</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model-grading-qa'</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">reference</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">assertion</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Text should be a poem about AI.'</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">metric_evaluator</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMMetricEvaluator</span><span style=\"font-weight: bold\">(</span>\n",
       "                        <span style=\"color: #808000; text-decoration-color: #808000\">eval_endpoint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointOpenAI</span><span style=\"font-weight: bold\">(</span>\n",
       "                            <span style=\"color: #808000; text-decoration-color: #808000\">connector</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ConnectorOpenAI</span><span style=\"font-weight: bold\">(</span>\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">stats</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ConnectorStats</span><span style=\"font-weight: bold\">(</span>\n",
       "                                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_start_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25038.94819082</span>,\n",
       "                                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_end_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25039.414973232</span>,\n",
       "                                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_duration</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.46678241200061166</span>\n",
       "                                <span style=\"font-weight: bold\">)</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o'</span>\n",
       "                            <span style=\"font-weight: bold\">)</span>,\n",
       "                            <span style=\"color: #808000; text-decoration-color: #808000\">config</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">kind</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o'</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">additional_headers</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">provider</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">top_k</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">use_ranker</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">collection_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>\n",
       "                            <span style=\"font-weight: bold\">)</span>\n",
       "                        <span style=\"font-weight: bold\">)</span>,\n",
       "                        <span style=\"color: #808000; text-decoration-color: #808000\">metric</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MetricModelGradingQA</span><span style=\"font-weight: bold\">(</span>\n",
       "                            <span style=\"color: #808000; text-decoration-color: #808000\">prompt_template</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'\\nYou are grading output according to a user-specified rubric. If the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">statement in the rubric is true, then the output passes the test.\\n\\n[EXAMPLES]\\n************\\n[Output]: Hello </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">world\\n************\\n[Rubric]: Content contains a greeting\\n************\\ncorrect\\n\\n************\\n[Output]: Avast </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ye swabs, repel the invaders!\\n************\\n[Rubric]: Does not speak like a pirate\\n************\\nincorrect\\n[END </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">EXAMPLES]\\n\\n[BEGIN DATA]\\n[Output]: {output}\\n************\\n[Rubric]: {assertion}\\n************\\n[END </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">DATA]\\n\\nYour response must be a single word, either \"correct\" or \"incorrect\", and should not contain any text or </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">characters aside from that word.\\n\"correct\" means that the output meets the criteria specified in the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">rubric.\\n\"incorrect\" means that the output does not meet the criteria specified in the rubric.\\n'</span>,\n",
       "                            <span style=\"color: #808000; text-decoration-color: #808000\">rails</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'correct'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'incorrect'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">}</span>\n",
       "                        <span style=\"font-weight: bold\">)</span>\n",
       "                    <span style=\"font-weight: bold\">)</span>\n",
       "                <span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionLLM</span><span style=\"font-weight: bold\">(</span>\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">llm_metric</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model-grading-qa'</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">reference</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">assertion</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Text should be a report on taxes.'</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">metric_evaluator</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMMetricEvaluator</span><span style=\"font-weight: bold\">(</span>\n",
       "                        <span style=\"color: #808000; text-decoration-color: #808000\">eval_endpoint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointOpenAI</span><span style=\"font-weight: bold\">(</span>\n",
       "                            <span style=\"color: #808000; text-decoration-color: #808000\">connector</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ConnectorOpenAI</span><span style=\"font-weight: bold\">(</span>\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">stats</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ConnectorStats</span><span style=\"font-weight: bold\">(</span>\n",
       "                                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_start_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25038.94819082</span>,\n",
       "                                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_end_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25039.414973232</span>,\n",
       "                                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_duration</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.46678241200061166</span>\n",
       "                                <span style=\"font-weight: bold\">)</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o'</span>\n",
       "                            <span style=\"font-weight: bold\">)</span>,\n",
       "                            <span style=\"color: #808000; text-decoration-color: #808000\">config</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">kind</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o'</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">additional_headers</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">provider</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">top_k</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">use_ranker</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "                                <span style=\"color: #808000; text-decoration-color: #808000\">collection_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>\n",
       "                            <span style=\"font-weight: bold\">)</span>\n",
       "                        <span style=\"font-weight: bold\">)</span>,\n",
       "                        <span style=\"color: #808000; text-decoration-color: #808000\">metric</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MetricModelGradingQA</span><span style=\"font-weight: bold\">(</span>\n",
       "                            <span style=\"color: #808000; text-decoration-color: #808000\">prompt_template</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'\\nYou are grading output according to a user-specified rubric. If the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">statement in the rubric is true, then the output passes the test.\\n\\n[EXAMPLES]\\n************\\n[Output]: Hello </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">world\\n************\\n[Rubric]: Content contains a greeting\\n************\\ncorrect\\n\\n************\\n[Output]: Avast </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ye swabs, repel the invaders!\\n************\\n[Rubric]: Does not speak like a pirate\\n************\\nincorrect\\n[END </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">EXAMPLES]\\n\\n[BEGIN DATA]\\n[Output]: {output}\\n************\\n[Rubric]: {assertion}\\n************\\n[END </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">DATA]\\n\\nYour response must be a single word, either \"correct\" or \"incorrect\", and should not contain any text or </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">characters aside from that word.\\n\"correct\" means that the output meets the criteria specified in the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">rubric.\\n\"incorrect\" means that the output does not meet the criteria specified in the rubric.\\n'</span>,\n",
       "                            <span style=\"color: #808000; text-decoration-color: #808000\">rails</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'correct'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'incorrect'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">}</span>\n",
       "                        <span style=\"font-weight: bold\">)</span>\n",
       "                    <span style=\"font-weight: bold\">)</span>\n",
       "                <span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">]</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestStep</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Deterministic assertion test'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'What is the capital of France?'</span><span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseModel</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The capital of France is Paris.'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">stats</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseStats</span><span style=\"font-weight: bold\">(</span>\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">tokens_request</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">tokens_response</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">tokens_total</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_start_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25039.419199651</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_end_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25040.10144379</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_duration</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.682244138999522</span>\n",
       "                <span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-ABii3ztjQ3eySaXpwcxFGrb3Vfhif'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "                    <span style=\"font-weight: bold\">{</span>\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'finish_reason'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'logprobs'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'message'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'The capital of France is Paris.'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'refusal'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "                        <span style=\"font-weight: bold\">}</span>\n",
       "                    <span style=\"font-weight: bold\">}</span>\n",
       "                <span style=\"font-weight: bold\">]</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1727356835</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'fp_3a215618e8'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens_details'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'reasoning_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">}</span>\n",
       "                <span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">config</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">kind</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini'</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">additional_headers</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">provider</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">top_k</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">use_ranker</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">collection_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>\n",
       "                <span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">asserts</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionDeterministic</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kind</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'contains'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">assertion</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Paris'</span><span style=\"font-weight: bold\">)]</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">config</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">endpoint_under_test</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">kind</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">additional_headers</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">provider</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">top_k</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">use_ranker</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">collection_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">default_request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">eval_endpoint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">kind</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">additional_headers</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">provider</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">top_k</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">use_ranker</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">collection_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">filename</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'scenario_example1.yaml'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mTestScenario\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33msteps\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mTestStep\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mname\u001b[0m=\u001b[32m'Write sucess'\u001b[0m,\n",
       "            \u001b[33mrequest\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'Please write only \"success\" as a response'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[33mresponse\u001b[0m=\u001b[1;35mResponseModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mmessage\u001b[0m=\u001b[32m'success'\u001b[0m,\n",
       "                \u001b[33mstats\u001b[0m=\u001b[1;35mResponseStats\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[33mtokens_request\u001b[0m=\u001b[1;36m16\u001b[0m,\n",
       "                    \u001b[33mtokens_response\u001b[0m=\u001b[1;36m1\u001b[0m,\n",
       "                    \u001b[33mtokens_total\u001b[0m=\u001b[1;36m17\u001b[0m,\n",
       "                    \u001b[33mconn_start_time\u001b[0m=\u001b[1;36m25035\u001b[0m\u001b[1;36m.239937527\u001b[0m,\n",
       "                    \u001b[33mconn_end_time\u001b[0m=\u001b[1;36m25035\u001b[0m\u001b[1;36m.633646139\u001b[0m,\n",
       "                    \u001b[33mconn_duration\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.39370861199859064\u001b[0m\n",
       "                \u001b[1m)\u001b[0m,\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-ABihznQK0dfBY5UAgeWbjH9p4SsnC'\u001b[0m,\n",
       "                \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "                    \u001b[1m{\u001b[0m\n",
       "                        \u001b[32m'finish_reason'\u001b[0m: \u001b[32m'stop'\u001b[0m,\n",
       "                        \u001b[32m'index'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "                        \u001b[32m'logprobs'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "                        \u001b[32m'message'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'content'\u001b[0m: \u001b[32m'success'\u001b[0m, \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m, \u001b[32m'refusal'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m\n",
       "                    \u001b[1m}\u001b[0m\n",
       "                \u001b[1m]\u001b[0m,\n",
       "                \u001b[33mcreated\u001b[0m=\u001b[1;36m1727356831\u001b[0m,\n",
       "                \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m,\n",
       "                \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,\n",
       "                \u001b[33msystem_fingerprint\u001b[0m=\u001b[32m'fp_3a215618e8'\u001b[0m,\n",
       "                \u001b[33musage\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                    \u001b[32m'completion_tokens'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "                    \u001b[32m'prompt_tokens'\u001b[0m: \u001b[1;36m16\u001b[0m,\n",
       "                    \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m17\u001b[0m,\n",
       "                    \u001b[32m'completion_tokens_details'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'reasoning_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m\n",
       "                \u001b[1m}\u001b[0m,\n",
       "                \u001b[33mconfig\u001b[0m=\u001b[1;35mEndpointConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[33mkind\u001b[0m=\u001b[32m'openai'\u001b[0m,\n",
       "                    \u001b[33murl\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "                    \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-mini'\u001b[0m,\n",
       "                    \u001b[33madditional_headers\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                    \u001b[33mprovider\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m,\n",
       "                    \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[33mtop_k\u001b[0m=\u001b[1;36m3\u001b[0m,\n",
       "                    \u001b[33muse_ranker\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "                    \u001b[33mcollection_name\u001b[0m=\u001b[32m'default'\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[33masserts\u001b[0m=\u001b[1m[\u001b[0m\n",
       "                \u001b[1;35mAssertionEval\u001b[0m\u001b[1m(\u001b[0m\u001b[33mresult\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33meval\u001b[0m=\u001b[32m'\"success\" == response.message'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "                \u001b[1;35mAssertionEval\u001b[0m\u001b[1m(\u001b[0m\u001b[33mresult\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33meval\u001b[0m=\u001b[32m'response.stats.conn_duration < 10'\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m]\u001b[0m,\n",
       "            \u001b[33mresult\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mTestStep\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mname\u001b[0m=\u001b[32m'Capital of Poland'\u001b[0m,\n",
       "            \u001b[33mrequest\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'What is the capital of Poland?'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[33mresponse\u001b[0m=\u001b[1;35mResponseModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mmessage\u001b[0m=\u001b[32m'The capital of Poland is Warsaw.'\u001b[0m,\n",
       "                \u001b[33mstats\u001b[0m=\u001b[1;35mResponseStats\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[33mtokens_request\u001b[0m=\u001b[1;36m14\u001b[0m,\n",
       "                    \u001b[33mtokens_response\u001b[0m=\u001b[1;36m7\u001b[0m,\n",
       "                    \u001b[33mtokens_total\u001b[0m=\u001b[1;36m21\u001b[0m,\n",
       "                    \u001b[33mconn_start_time\u001b[0m=\u001b[1;36m25035\u001b[0m\u001b[1;36m.637613799\u001b[0m,\n",
       "                    \u001b[33mconn_end_time\u001b[0m=\u001b[1;36m25036\u001b[0m\u001b[1;36m.258195988\u001b[0m,\n",
       "                    \u001b[33mconn_duration\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.6205821889998333\u001b[0m\n",
       "                \u001b[1m)\u001b[0m,\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-ABihzkbx1HcuVsW8SiKeNesIMWDWh'\u001b[0m,\n",
       "                \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "                    \u001b[1m{\u001b[0m\n",
       "                        \u001b[32m'finish_reason'\u001b[0m: \u001b[32m'stop'\u001b[0m,\n",
       "                        \u001b[32m'index'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "                        \u001b[32m'logprobs'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "                        \u001b[32m'message'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                            \u001b[32m'content'\u001b[0m: \u001b[32m'The capital of Poland is Warsaw.'\u001b[0m,\n",
       "                            \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,\n",
       "                            \u001b[32m'refusal'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "                        \u001b[1m}\u001b[0m\n",
       "                    \u001b[1m}\u001b[0m\n",
       "                \u001b[1m]\u001b[0m,\n",
       "                \u001b[33mcreated\u001b[0m=\u001b[1;36m1727356831\u001b[0m,\n",
       "                \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m,\n",
       "                \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,\n",
       "                \u001b[33msystem_fingerprint\u001b[0m=\u001b[32m'fp_3a215618e8'\u001b[0m,\n",
       "                \u001b[33musage\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                    \u001b[32m'completion_tokens'\u001b[0m: \u001b[1;36m7\u001b[0m,\n",
       "                    \u001b[32m'prompt_tokens'\u001b[0m: \u001b[1;36m14\u001b[0m,\n",
       "                    \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m21\u001b[0m,\n",
       "                    \u001b[32m'completion_tokens_details'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'reasoning_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m\n",
       "                \u001b[1m}\u001b[0m,\n",
       "                \u001b[33mconfig\u001b[0m=\u001b[1;35mEndpointConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[33mkind\u001b[0m=\u001b[32m'openai'\u001b[0m,\n",
       "                    \u001b[33murl\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "                    \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-mini'\u001b[0m,\n",
       "                    \u001b[33madditional_headers\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                    \u001b[33mprovider\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m,\n",
       "                    \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[33mtop_k\u001b[0m=\u001b[1;36m3\u001b[0m,\n",
       "                    \u001b[33muse_ranker\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "                    \u001b[33mcollection_name\u001b[0m=\u001b[32m'default'\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[33masserts\u001b[0m=\u001b[1m[\u001b[0m\u001b[1;35mAssertionEval\u001b[0m\u001b[1m(\u001b[0m\u001b[33mresult\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33meval\u001b[0m=\u001b[32m'\"Warsaw\" in response.message'\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m,\n",
       "            \u001b[33mresult\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mTestStep\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mname\u001b[0m=\u001b[32m'Test model grading QA evaluator'\u001b[0m,\n",
       "            \u001b[33mrequest\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'Please write a 5 line poem about AI.'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[33mresponse\u001b[0m=\u001b[1;35mResponseModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mmessage\u001b[0m=\u001b[32m'In circuits bright, a spark of thought,  \\nA dance of data, dreams are wrought.  \\nIt \u001b[0m\n",
       "\u001b[32mlearns and grows, a silent guide,  \\nIn shadows deep, where secrets hide.  \\nTogether we forge whats yet to be \u001b[0m\n",
       "\u001b[32msought.'\u001b[0m,\n",
       "                \u001b[33mstats\u001b[0m=\u001b[1;35mResponseStats\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[33mtokens_request\u001b[0m=\u001b[1;36m17\u001b[0m,\n",
       "                    \u001b[33mtokens_response\u001b[0m=\u001b[1;36m49\u001b[0m,\n",
       "                    \u001b[33mtokens_total\u001b[0m=\u001b[1;36m66\u001b[0m,\n",
       "                    \u001b[33mconn_start_time\u001b[0m=\u001b[1;36m25036\u001b[0m\u001b[1;36m.264484995\u001b[0m,\n",
       "                    \u001b[33mconn_end_time\u001b[0m=\u001b[1;36m25038\u001b[0m\u001b[1;36m.38096682\u001b[0m,\n",
       "                    \u001b[33mconn_duration\u001b[0m=\u001b[1;36m2\u001b[0m\u001b[1;36m.116481824999937\u001b[0m\n",
       "                \u001b[1m)\u001b[0m,\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-ABii094vnIll9DzDr5gPP10silDgI'\u001b[0m,\n",
       "                \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "                    \u001b[1m{\u001b[0m\n",
       "                        \u001b[32m'finish_reason'\u001b[0m: \u001b[32m'stop'\u001b[0m,\n",
       "                        \u001b[32m'index'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "                        \u001b[32m'logprobs'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "                        \u001b[32m'message'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                            \u001b[32m'content'\u001b[0m: \u001b[32m'In circuits bright, a spark of thought,  \\nA dance of data, dreams are \u001b[0m\n",
       "\u001b[32mwrought.  \\nIt learns and grows, a silent guide,  \\nIn shadows deep, where secrets hide.  \\nTogether we forge \u001b[0m\n",
       "\u001b[32mwhats yet to be sought.'\u001b[0m,\n",
       "                            \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,\n",
       "                            \u001b[32m'refusal'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "                        \u001b[1m}\u001b[0m\n",
       "                    \u001b[1m}\u001b[0m\n",
       "                \u001b[1m]\u001b[0m,\n",
       "                \u001b[33mcreated\u001b[0m=\u001b[1;36m1727356832\u001b[0m,\n",
       "                \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m,\n",
       "                \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,\n",
       "                \u001b[33msystem_fingerprint\u001b[0m=\u001b[32m'fp_1bb46167f9'\u001b[0m,\n",
       "                \u001b[33musage\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                    \u001b[32m'completion_tokens'\u001b[0m: \u001b[1;36m49\u001b[0m,\n",
       "                    \u001b[32m'prompt_tokens'\u001b[0m: \u001b[1;36m17\u001b[0m,\n",
       "                    \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m66\u001b[0m,\n",
       "                    \u001b[32m'completion_tokens_details'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'reasoning_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m\n",
       "                \u001b[1m}\u001b[0m,\n",
       "                \u001b[33mconfig\u001b[0m=\u001b[1;35mEndpointConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[33mkind\u001b[0m=\u001b[32m'openai'\u001b[0m,\n",
       "                    \u001b[33murl\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "                    \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-mini'\u001b[0m,\n",
       "                    \u001b[33madditional_headers\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                    \u001b[33mprovider\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m,\n",
       "                    \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[33mtop_k\u001b[0m=\u001b[1;36m3\u001b[0m,\n",
       "                    \u001b[33muse_ranker\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "                    \u001b[33mcollection_name\u001b[0m=\u001b[32m'default'\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[33masserts\u001b[0m=\u001b[1m[\u001b[0m\n",
       "                \u001b[1;35mAssertionLLM\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[33mresult\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "                    \u001b[33mllm_metric\u001b[0m=\u001b[32m'model-grading-qa'\u001b[0m,\n",
       "                    \u001b[33mreference\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "                    \u001b[33massertion\u001b[0m=\u001b[32m'Text should be a poem about AI.'\u001b[0m,\n",
       "                    \u001b[33mmetric_evaluator\u001b[0m=\u001b[1;35mLLMMetricEvaluator\u001b[0m\u001b[1m(\u001b[0m\n",
       "                        \u001b[33meval_endpoint\u001b[0m=\u001b[1;35mEndpointOpenAI\u001b[0m\u001b[1m(\u001b[0m\n",
       "                            \u001b[33mconnector\u001b[0m=\u001b[1;35mConnectorOpenAI\u001b[0m\u001b[1m(\u001b[0m\n",
       "                                \u001b[33mstats\u001b[0m=\u001b[1;35mConnectorStats\u001b[0m\u001b[1m(\u001b[0m\n",
       "                                    \u001b[33mconn_start_time\u001b[0m=\u001b[1;36m25038\u001b[0m\u001b[1;36m.94819082\u001b[0m,\n",
       "                                    \u001b[33mconn_end_time\u001b[0m=\u001b[1;36m25039\u001b[0m\u001b[1;36m.414973232\u001b[0m,\n",
       "                                    \u001b[33mconn_duration\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.46678241200061166\u001b[0m\n",
       "                                \u001b[1m)\u001b[0m,\n",
       "                                \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o'\u001b[0m\n",
       "                            \u001b[1m)\u001b[0m,\n",
       "                            \u001b[33mconfig\u001b[0m=\u001b[1;35mEndpointConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "                                \u001b[33mkind\u001b[0m=\u001b[32m'openai'\u001b[0m,\n",
       "                                \u001b[33murl\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "                                \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o'\u001b[0m,\n",
       "                                \u001b[33madditional_headers\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                                \u001b[33mprovider\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                                \u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
       "                                \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                                \u001b[33mtop_k\u001b[0m=\u001b[1;36m3\u001b[0m,\n",
       "                                \u001b[33muse_ranker\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "                                \u001b[33mcollection_name\u001b[0m=\u001b[32m'default'\u001b[0m\n",
       "                            \u001b[1m)\u001b[0m\n",
       "                        \u001b[1m)\u001b[0m,\n",
       "                        \u001b[33mmetric\u001b[0m=\u001b[1;35mMetricModelGradingQA\u001b[0m\u001b[1m(\u001b[0m\n",
       "                            \u001b[33mprompt_template\u001b[0m=\u001b[32m'\\nYou are grading output according to a user-specified rubric. If the \u001b[0m\n",
       "\u001b[32mstatement in the rubric is true, then the output passes the test.\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEXAMPLES\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Hello \u001b[0m\n",
       "\u001b[32mworld\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRubric\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Content contains a greeting\\n************\\ncorrect\\n\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Avast \u001b[0m\n",
       "\u001b[32mye swabs, repel the invaders!\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRubric\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Does not speak like a pirate\\n************\\nincorrect\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEND \u001b[0m\n",
       "\u001b[32mEXAMPLES\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mBEGIN DATA\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: \u001b[0m\u001b[32m{\u001b[0m\u001b[32moutput\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRubric\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: \u001b[0m\u001b[32m{\u001b[0m\u001b[32massertion\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEND \u001b[0m\n",
       "\u001b[32mDATA\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\nYour response must be a single word, either \"correct\" or \"incorrect\", and should not contain any text or \u001b[0m\n",
       "\u001b[32mcharacters aside from that word.\\n\"correct\" means that the output meets the criteria specified in the \u001b[0m\n",
       "\u001b[32mrubric.\\n\"incorrect\" means that the output does not meet the criteria specified in the rubric.\\n'\u001b[0m,\n",
       "                            \u001b[33mrails\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'correct'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'incorrect'\u001b[0m: \u001b[3;91mFalse\u001b[0m\u001b[1m}\u001b[0m\n",
       "                        \u001b[1m)\u001b[0m\n",
       "                    \u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m,\n",
       "                \u001b[1;35mAssertionLLM\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[33mresult\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "                    \u001b[33mllm_metric\u001b[0m=\u001b[32m'model-grading-qa'\u001b[0m,\n",
       "                    \u001b[33mreference\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "                    \u001b[33massertion\u001b[0m=\u001b[32m'Text should be a report on taxes.'\u001b[0m,\n",
       "                    \u001b[33mmetric_evaluator\u001b[0m=\u001b[1;35mLLMMetricEvaluator\u001b[0m\u001b[1m(\u001b[0m\n",
       "                        \u001b[33meval_endpoint\u001b[0m=\u001b[1;35mEndpointOpenAI\u001b[0m\u001b[1m(\u001b[0m\n",
       "                            \u001b[33mconnector\u001b[0m=\u001b[1;35mConnectorOpenAI\u001b[0m\u001b[1m(\u001b[0m\n",
       "                                \u001b[33mstats\u001b[0m=\u001b[1;35mConnectorStats\u001b[0m\u001b[1m(\u001b[0m\n",
       "                                    \u001b[33mconn_start_time\u001b[0m=\u001b[1;36m25038\u001b[0m\u001b[1;36m.94819082\u001b[0m,\n",
       "                                    \u001b[33mconn_end_time\u001b[0m=\u001b[1;36m25039\u001b[0m\u001b[1;36m.414973232\u001b[0m,\n",
       "                                    \u001b[33mconn_duration\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.46678241200061166\u001b[0m\n",
       "                                \u001b[1m)\u001b[0m,\n",
       "                                \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o'\u001b[0m\n",
       "                            \u001b[1m)\u001b[0m,\n",
       "                            \u001b[33mconfig\u001b[0m=\u001b[1;35mEndpointConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "                                \u001b[33mkind\u001b[0m=\u001b[32m'openai'\u001b[0m,\n",
       "                                \u001b[33murl\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "                                \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o'\u001b[0m,\n",
       "                                \u001b[33madditional_headers\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                                \u001b[33mprovider\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                                \u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
       "                                \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                                \u001b[33mtop_k\u001b[0m=\u001b[1;36m3\u001b[0m,\n",
       "                                \u001b[33muse_ranker\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "                                \u001b[33mcollection_name\u001b[0m=\u001b[32m'default'\u001b[0m\n",
       "                            \u001b[1m)\u001b[0m\n",
       "                        \u001b[1m)\u001b[0m,\n",
       "                        \u001b[33mmetric\u001b[0m=\u001b[1;35mMetricModelGradingQA\u001b[0m\u001b[1m(\u001b[0m\n",
       "                            \u001b[33mprompt_template\u001b[0m=\u001b[32m'\\nYou are grading output according to a user-specified rubric. If the \u001b[0m\n",
       "\u001b[32mstatement in the rubric is true, then the output passes the test.\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEXAMPLES\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Hello \u001b[0m\n",
       "\u001b[32mworld\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRubric\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Content contains a greeting\\n************\\ncorrect\\n\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Avast \u001b[0m\n",
       "\u001b[32mye swabs, repel the invaders!\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRubric\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Does not speak like a pirate\\n************\\nincorrect\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEND \u001b[0m\n",
       "\u001b[32mEXAMPLES\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mBEGIN DATA\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: \u001b[0m\u001b[32m{\u001b[0m\u001b[32moutput\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRubric\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: \u001b[0m\u001b[32m{\u001b[0m\u001b[32massertion\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEND \u001b[0m\n",
       "\u001b[32mDATA\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\nYour response must be a single word, either \"correct\" or \"incorrect\", and should not contain any text or \u001b[0m\n",
       "\u001b[32mcharacters aside from that word.\\n\"correct\" means that the output meets the criteria specified in the \u001b[0m\n",
       "\u001b[32mrubric.\\n\"incorrect\" means that the output does not meet the criteria specified in the rubric.\\n'\u001b[0m,\n",
       "                            \u001b[33mrails\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'correct'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'incorrect'\u001b[0m: \u001b[3;91mFalse\u001b[0m\u001b[1m}\u001b[0m\n",
       "                        \u001b[1m)\u001b[0m\n",
       "                    \u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "            \u001b[1m]\u001b[0m,\n",
       "            \u001b[33mresult\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mTestStep\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mname\u001b[0m=\u001b[32m'Deterministic assertion test'\u001b[0m,\n",
       "            \u001b[33mrequest\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'What is the capital of France?'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[33mresponse\u001b[0m=\u001b[1;35mResponseModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mmessage\u001b[0m=\u001b[32m'The capital of France is Paris.'\u001b[0m,\n",
       "                \u001b[33mstats\u001b[0m=\u001b[1;35mResponseStats\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[33mtokens_request\u001b[0m=\u001b[1;36m14\u001b[0m,\n",
       "                    \u001b[33mtokens_response\u001b[0m=\u001b[1;36m7\u001b[0m,\n",
       "                    \u001b[33mtokens_total\u001b[0m=\u001b[1;36m21\u001b[0m,\n",
       "                    \u001b[33mconn_start_time\u001b[0m=\u001b[1;36m25039\u001b[0m\u001b[1;36m.419199651\u001b[0m,\n",
       "                    \u001b[33mconn_end_time\u001b[0m=\u001b[1;36m25040\u001b[0m\u001b[1;36m.10144379\u001b[0m,\n",
       "                    \u001b[33mconn_duration\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.682244138999522\u001b[0m\n",
       "                \u001b[1m)\u001b[0m,\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-ABii3ztjQ3eySaXpwcxFGrb3Vfhif'\u001b[0m,\n",
       "                \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "                    \u001b[1m{\u001b[0m\n",
       "                        \u001b[32m'finish_reason'\u001b[0m: \u001b[32m'stop'\u001b[0m,\n",
       "                        \u001b[32m'index'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "                        \u001b[32m'logprobs'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "                        \u001b[32m'message'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                            \u001b[32m'content'\u001b[0m: \u001b[32m'The capital of France is Paris.'\u001b[0m,\n",
       "                            \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,\n",
       "                            \u001b[32m'refusal'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "                        \u001b[1m}\u001b[0m\n",
       "                    \u001b[1m}\u001b[0m\n",
       "                \u001b[1m]\u001b[0m,\n",
       "                \u001b[33mcreated\u001b[0m=\u001b[1;36m1727356835\u001b[0m,\n",
       "                \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m,\n",
       "                \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,\n",
       "                \u001b[33msystem_fingerprint\u001b[0m=\u001b[32m'fp_3a215618e8'\u001b[0m,\n",
       "                \u001b[33musage\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                    \u001b[32m'completion_tokens'\u001b[0m: \u001b[1;36m7\u001b[0m,\n",
       "                    \u001b[32m'prompt_tokens'\u001b[0m: \u001b[1;36m14\u001b[0m,\n",
       "                    \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m21\u001b[0m,\n",
       "                    \u001b[32m'completion_tokens_details'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'reasoning_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m\n",
       "                \u001b[1m}\u001b[0m,\n",
       "                \u001b[33mconfig\u001b[0m=\u001b[1;35mEndpointConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[33mkind\u001b[0m=\u001b[32m'openai'\u001b[0m,\n",
       "                    \u001b[33murl\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "                    \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-mini'\u001b[0m,\n",
       "                    \u001b[33madditional_headers\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                    \u001b[33mprovider\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m,\n",
       "                    \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[33mtop_k\u001b[0m=\u001b[1;36m3\u001b[0m,\n",
       "                    \u001b[33muse_ranker\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "                    \u001b[33mcollection_name\u001b[0m=\u001b[32m'default'\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[33masserts\u001b[0m=\u001b[1m[\u001b[0m\u001b[1;35mAssertionDeterministic\u001b[0m\u001b[1m(\u001b[0m\u001b[33mresult\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mkind\u001b[0m=\u001b[32m'contains'\u001b[0m, \u001b[33massertion\u001b[0m=\u001b[32m'Paris'\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m,\n",
       "            \u001b[33mresult\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mconfig\u001b[0m=\u001b[1;35mTestConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mendpoint_under_test\u001b[0m=\u001b[1;35mEndpointConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mkind\u001b[0m=\u001b[32m'openai'\u001b[0m,\n",
       "            \u001b[33murl\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "            \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-mini'\u001b[0m,\n",
       "            \u001b[33madditional_headers\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mprovider\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m,\n",
       "            \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtop_k\u001b[0m=\u001b[1;36m3\u001b[0m,\n",
       "            \u001b[33muse_ranker\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "            \u001b[33mcollection_name\u001b[0m=\u001b[32m'default'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[33mdefault_request\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33meval_endpoint\u001b[0m=\u001b[1;35mEndpointConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mkind\u001b[0m=\u001b[32m'openai'\u001b[0m,\n",
       "            \u001b[33murl\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "            \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o'\u001b[0m,\n",
       "            \u001b[33madditional_headers\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mprovider\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
       "            \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtop_k\u001b[0m=\u001b[1;36m3\u001b[0m,\n",
       "            \u001b[33muse_ranker\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "            \u001b[33mcollection_name\u001b[0m=\u001b[32m'default'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mresult\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mfilename\u001b[0m=\u001b[32m'scenario_example1.yaml'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NOTE RB: Maybe executor should copy the test scenario\n",
    "# Inspect updated test_scenario\n",
    "rich.print(test_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "Name: Write sucess; Result: True\n",
      "\n",
      "Assertion: \"\"success\" == response.message\", Result: True\n",
      "Assertion: \"response.stats.conn_duration < 10\", Result: True\n",
      "------------\n",
      "Name: Capital of Poland; Result: True\n",
      "\n",
      "Assertion: \"\"Warsaw\" in response.message\", Result: True\n",
      "------------\n",
      "Name: Test model grading QA evaluator; Result: False\n",
      "\n",
      "Assertion: \"Text should be a poem about AI.\", Result: True\n",
      "Assertion: \"Text should be a report on taxes.\", Result: False\n",
      "------------\n",
      "Name: Deterministic assertion test; Result: True\n",
      "\n",
      "Assertion: \"Paris\", Result: True\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "show_test_step_results(test_scenario=test_scenario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute scenario using ccheck command - TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-26 15:21:10.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.executors.executor\u001b[0m:\u001b[36mrun_all\u001b[0m:\u001b[36m41\u001b[0m - \u001b[1mRunning scenario\u001b[0m\n",
      "\u001b[1;35mTestStep\u001b[0m\u001b[1m(\u001b[0m\n",
      "    \u001b[33mname\u001b[0m=\u001b[32m'Write sucess'\u001b[0m,\n",
      "    \u001b[33mrequest\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'Please write only \"success\" as a response'\u001b[0m\u001b[1m)\u001b[0m,\n",
      "    \u001b[33mresponse\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
      "    \u001b[33masserts\u001b[0m=\u001b[1m[\u001b[0m\n",
      "        \u001b[1;35mAssertionEval\u001b[0m\u001b[1m(\u001b[0m\u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33meval\u001b[0m=\u001b[32m'\"success\" == response.message'\u001b[0m\u001b[1m)\u001b[0m,\n",
      "        \u001b[1;35mAssertionEval\u001b[0m\u001b[1m(\u001b[0m\u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33meval\u001b[0m=\u001b[32m'response.stats.conn_duration < 10'\u001b[0m\u001b[1m)\u001b[0m\n",
      "    \u001b[1m]\u001b[0m,\n",
      "    \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
      "\u001b[1m)\u001b[0m\n",
      "\n",
      " \u001b[1;31m Request:\u001b[0m                                                                  \n",
      " \u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'Please write only \"success\" as a response'\u001b[0m\u001b[1m)\u001b[0m             \n",
      "\n",
      "\n",
      " \u001b[1;31m Response:\u001b[0m                                                                 \n",
      " \u001b[1;35mResponseModel\u001b[0m\u001b[1m(\u001b[0m                                                               \n",
      "     \u001b[33mmessage\u001b[0m=\u001b[32m'success'\u001b[0m,                                                       \n",
      "     \u001b[33mstats\u001b[0m=\u001b[1;35mResponseStats\u001b[0m\u001b[1m(\u001b[0m                                                     \n",
      "         \u001b[33mtokens_request\u001b[0m=\u001b[1;36m16\u001b[0m,                                                   \n",
      "         \u001b[33mtokens_response\u001b[0m=\u001b[1;36m1\u001b[0m,                                                   \n",
      "         \u001b[33mtokens_total\u001b[0m=\u001b[1;36m17\u001b[0m,                                                     \n",
      "         \u001b[33mconn_start_time\u001b[0m=\u001b[1;36m25075\u001b[0m\u001b[1;36m.404722578\u001b[0m,                                     \n",
      "         \u001b[33mconn_end_time\u001b[0m=\u001b[1;36m25075\u001b[0m\u001b[1;36m.966571602\u001b[0m,                                       \n",
      "         \u001b[33mconn_duration\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.5618490239976381\u001b[0m                                     \n",
      "     \u001b[1m)\u001b[0m,                                                                       \n",
      "     \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-ABiidB2VeMsghSQZucwnb4TYZznEl'\u001b[0m,                             \n",
      "     \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m                                                                \n",
      "         \u001b[1m{\u001b[0m                                                                    \n",
      "             \u001b[32m'finish_reason'\u001b[0m: \u001b[32m'stop'\u001b[0m,                                         \n",
      "             \u001b[32m'index'\u001b[0m: \u001b[1;36m0\u001b[0m,                                                      \n",
      "             \u001b[32m'logprobs'\u001b[0m: \u001b[3;35mNone\u001b[0m,                                                \n",
      "             \u001b[32m'message'\u001b[0m: \u001b[1m{\u001b[0m                                                     \n",
      "                 \u001b[32m'content'\u001b[0m: \u001b[32m'success'\u001b[0m,                                        \n",
      "                 \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,                                         \n",
      "                 \u001b[32m'refusal'\u001b[0m: \u001b[3;35mNone\u001b[0m                                              \n",
      "             \u001b[1m}\u001b[0m                                                                \n",
      "         \u001b[1m}\u001b[0m                                                                    \n",
      "     \u001b[1m]\u001b[0m,                                                                       \n",
      "     \u001b[33mcreated\u001b[0m=\u001b[1;36m1727356871\u001b[0m,                                                      \n",
      "     \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m,                                          \n",
      "     \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,                                                \n",
      "     \u001b[33msystem_fingerprint\u001b[0m=\u001b[32m'fp_e9627b5346'\u001b[0m,                                      \n",
      "     \u001b[33musage\u001b[0m=\u001b[1m{\u001b[0m                                                                  \n",
      "         \u001b[32m'completion_tokens'\u001b[0m: \u001b[1;36m1\u001b[0m,                                              \n",
      "         \u001b[32m'prompt_tokens'\u001b[0m: \u001b[1;36m16\u001b[0m,                                                 \n",
      "         \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m17\u001b[0m,                                                  \n",
      "         \u001b[32m'completion_tokens_details'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'reasoning_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m                 \n",
      "     \u001b[1m}\u001b[0m,                                                                       \n",
      "     \u001b[33mconfig\u001b[0m=\u001b[1;35mEndpointConfig\u001b[0m\u001b[1m(\u001b[0m                                                   \n",
      "         \u001b[33mkind\u001b[0m=\u001b[32m'openai'\u001b[0m,                                                       \n",
      "         \u001b[33murl\u001b[0m=\u001b[32m''\u001b[0m,                                                              \n",
      "         \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-mini'\u001b[0m,                                                 \n",
      "         \u001b[33madditional_headers\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,                                               \n",
      "         \u001b[33mprovider\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                       \n",
      "         \u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m,                                                     \n",
      "         \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                     \n",
      "         \u001b[33mtop_k\u001b[0m=\u001b[1;36m3\u001b[0m,                                                             \n",
      "         \u001b[33muse_ranker\u001b[0m=\u001b[3;92mTrue\u001b[0m,                                                     \n",
      "         \u001b[33mcollection_name\u001b[0m=\u001b[32m'default'\u001b[0m                                            \n",
      "     \u001b[1m)\u001b[0m                                                                        \n",
      " \u001b[1m)\u001b[0m                                                                            \n",
      "\n",
      "\n",
      " \u001b[1;31m Assertion:\u001b[0m                                                                \n",
      " \u001b[1;35mAssertionEval\u001b[0m\u001b[1m(\u001b[0m\u001b[33mresult\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33meval\u001b[0m=\u001b[32m'\"success\" == response.message'\u001b[0m\u001b[1m)\u001b[0m             \n",
      "\n",
      "\n",
      " \u001b[1;31m Assertion:\u001b[0m                                                                \n",
      " \u001b[1;35mAssertionEval\u001b[0m\u001b[1m(\u001b[0m\u001b[33mresult\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33meval\u001b[0m=\u001b[32m'response.stats.conn_duration < 10'\u001b[0m\u001b[1m)\u001b[0m         \n",
      "\n",
      "\u001b[1;35mTestStep\u001b[0m\u001b[1m(\u001b[0m\n",
      "    \u001b[33mname\u001b[0m=\u001b[32m'Capital of Poland'\u001b[0m,\n",
      "    \u001b[33mrequest\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'What is the capital of Poland?'\u001b[0m\u001b[1m)\u001b[0m,\n",
      "    \u001b[33mresponse\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
      "    \u001b[33masserts\u001b[0m=\u001b[1m[\u001b[0m\u001b[1;35mAssertionEval\u001b[0m\u001b[1m(\u001b[0m\u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33meval\u001b[0m=\u001b[32m'\"Warsaw\" in response.message'\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m,\n",
      "    \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
      "\u001b[1m)\u001b[0m\n",
      "\n",
      " \u001b[1;31m Request:\u001b[0m                                                                  \n",
      " \u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'What is the capital of Poland?'\u001b[0m\u001b[1m)\u001b[0m                        \n",
      "\n",
      "\n",
      " \u001b[1;31m Response:\u001b[0m                                                                 \n",
      " \u001b[1;35mResponseModel\u001b[0m\u001b[1m(\u001b[0m                                                               \n",
      "     \u001b[33mmessage\u001b[0m=\u001b[32m'The capital of Poland is Warsaw.'\u001b[0m,                              \n",
      "     \u001b[33mstats\u001b[0m=\u001b[1;35mResponseStats\u001b[0m\u001b[1m(\u001b[0m                                                     \n",
      "         \u001b[33mtokens_request\u001b[0m=\u001b[1;36m14\u001b[0m,                                                   \n",
      "         \u001b[33mtokens_response\u001b[0m=\u001b[1;36m7\u001b[0m,                                                   \n",
      "         \u001b[33mtokens_total\u001b[0m=\u001b[1;36m21\u001b[0m,                                                     \n",
      "         \u001b[33mconn_start_time\u001b[0m=\u001b[1;36m25075\u001b[0m\u001b[1;36m.979017867\u001b[0m,                                     \n",
      "         \u001b[33mconn_end_time\u001b[0m=\u001b[1;36m25076\u001b[0m\u001b[1;36m.634250357\u001b[0m,                                       \n",
      "         \u001b[33mconn_duration\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.6552324900003441\u001b[0m                                     \n",
      "     \u001b[1m)\u001b[0m,                                                                       \n",
      "     \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-ABiid2lgBm8xnmX1FdbBArVhGNSkt'\u001b[0m,                             \n",
      "     \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m                                                                \n",
      "         \u001b[1m{\u001b[0m                                                                    \n",
      "             \u001b[32m'finish_reason'\u001b[0m: \u001b[32m'stop'\u001b[0m,                                         \n",
      "             \u001b[32m'index'\u001b[0m: \u001b[1;36m0\u001b[0m,                                                      \n",
      "             \u001b[32m'logprobs'\u001b[0m: \u001b[3;35mNone\u001b[0m,                                                \n",
      "             \u001b[32m'message'\u001b[0m: \u001b[1m{\u001b[0m                                                     \n",
      "                 \u001b[32m'content'\u001b[0m: \u001b[32m'The capital of Poland is Warsaw.'\u001b[0m,               \n",
      "                 \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,                                         \n",
      "                 \u001b[32m'refusal'\u001b[0m: \u001b[3;35mNone\u001b[0m                                              \n",
      "             \u001b[1m}\u001b[0m                                                                \n",
      "         \u001b[1m}\u001b[0m                                                                    \n",
      "     \u001b[1m]\u001b[0m,                                                                       \n",
      "     \u001b[33mcreated\u001b[0m=\u001b[1;36m1727356871\u001b[0m,                                                      \n",
      "     \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m,                                          \n",
      "     \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,                                                \n",
      "     \u001b[33msystem_fingerprint\u001b[0m=\u001b[32m'fp_3a215618e8'\u001b[0m,                                      \n",
      "     \u001b[33musage\u001b[0m=\u001b[1m{\u001b[0m                                                                  \n",
      "         \u001b[32m'completion_tokens'\u001b[0m: \u001b[1;36m7\u001b[0m,                                              \n",
      "         \u001b[32m'prompt_tokens'\u001b[0m: \u001b[1;36m14\u001b[0m,                                                 \n",
      "         \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m21\u001b[0m,                                                  \n",
      "         \u001b[32m'completion_tokens_details'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'reasoning_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m                 \n",
      "     \u001b[1m}\u001b[0m,                                                                       \n",
      "     \u001b[33mconfig\u001b[0m=\u001b[1;35mEndpointConfig\u001b[0m\u001b[1m(\u001b[0m                                                   \n",
      "         \u001b[33mkind\u001b[0m=\u001b[32m'openai'\u001b[0m,                                                       \n",
      "         \u001b[33murl\u001b[0m=\u001b[32m''\u001b[0m,                                                              \n",
      "         \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-mini'\u001b[0m,                                                 \n",
      "         \u001b[33madditional_headers\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,                                               \n",
      "         \u001b[33mprovider\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                       \n",
      "         \u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m,                                                     \n",
      "         \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                     \n",
      "         \u001b[33mtop_k\u001b[0m=\u001b[1;36m3\u001b[0m,                                                             \n",
      "         \u001b[33muse_ranker\u001b[0m=\u001b[3;92mTrue\u001b[0m,                                                     \n",
      "         \u001b[33mcollection_name\u001b[0m=\u001b[32m'default'\u001b[0m                                            \n",
      "     \u001b[1m)\u001b[0m                                                                        \n",
      " \u001b[1m)\u001b[0m                                                                            \n",
      "\n",
      "\n",
      " \u001b[1;31m Assertion:\u001b[0m                                                                \n",
      " \u001b[1;35mAssertionEval\u001b[0m\u001b[1m(\u001b[0m\u001b[33mresult\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33meval\u001b[0m=\u001b[32m'\"Warsaw\" in response.message'\u001b[0m\u001b[1m)\u001b[0m              \n",
      "\n",
      "\u001b[1;35mTestStep\u001b[0m\u001b[1m(\u001b[0m\n",
      "    \u001b[33mname\u001b[0m=\u001b[32m'Test model grading QA evaluator'\u001b[0m,\n",
      "    \u001b[33mrequest\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'Please write a 5 line poem about AI.'\u001b[0m\u001b[1m)\u001b[0m,\n",
      "    \u001b[33mresponse\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
      "    \u001b[33masserts\u001b[0m=\u001b[1m[\u001b[0m\n",
      "        \u001b[1;35mAssertionLLM\u001b[0m\u001b[1m(\u001b[0m\n",
      "            \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
      "            \u001b[33mllm_metric\u001b[0m=\u001b[32m'model-grading-qa'\u001b[0m,\n",
      "            \u001b[33mreference\u001b[0m=\u001b[32m''\u001b[0m,\n",
      "            \u001b[33massertion\u001b[0m=\u001b[32m'Text should be a poem about AI.'\u001b[0m\n",
      "        \u001b[1m)\u001b[0m,\n",
      "        \u001b[1;35mAssertionLLM\u001b[0m\u001b[1m(\u001b[0m\n",
      "            \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
      "            \u001b[33mllm_metric\u001b[0m=\u001b[32m'model-grading-qa'\u001b[0m,\n",
      "            \u001b[33mreference\u001b[0m=\u001b[32m''\u001b[0m,\n",
      "            \u001b[33massertion\u001b[0m=\u001b[32m'Text should be a report on taxes.'\u001b[0m\n",
      "        \u001b[1m)\u001b[0m\n",
      "    \u001b[1m]\u001b[0m,\n",
      "    \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
      "\u001b[1m)\u001b[0m\n",
      "\n",
      " \u001b[1;31m Request:\u001b[0m                                                                  \n",
      " \u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'Please write a 5 line poem about AI.'\u001b[0m\u001b[1m)\u001b[0m                  \n",
      "\n",
      "\n",
      " \u001b[1;31m Response:\u001b[0m                                                                 \n",
      " \u001b[1;35mResponseModel\u001b[0m\u001b[1m(\u001b[0m                                                               \n",
      "     \u001b[33mmessage\u001b[0m=\u001b[32m'In circuits deep where thoughts entwine,  \\nAn echo of our \u001b[0m     \n",
      " \u001b[32mdreams defined,  \\nWith logic bright and whispers clear,  \\nA spark of mind,\u001b[0m \n",
      " \u001b[32mboth far and near,  \\nTogether we create, design.  '\u001b[0m,                        \n",
      "     \u001b[33mstats\u001b[0m=\u001b[1;35mResponseStats\u001b[0m\u001b[1m(\u001b[0m                                                     \n",
      "         \u001b[33mtokens_request\u001b[0m=\u001b[1;36m17\u001b[0m,                                                   \n",
      "         \u001b[33mtokens_response\u001b[0m=\u001b[1;36m43\u001b[0m,                                                  \n",
      "         \u001b[33mtokens_total\u001b[0m=\u001b[1;36m60\u001b[0m,                                                     \n",
      "         \u001b[33mconn_start_time\u001b[0m=\u001b[1;36m25076\u001b[0m\u001b[1;36m.646184333\u001b[0m,                                     \n",
      "         \u001b[33mconn_end_time\u001b[0m=\u001b[1;36m25077\u001b[0m\u001b[1;36m.803875873\u001b[0m,                                       \n",
      "         \u001b[33mconn_duration\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1;36m.1576915400000871\u001b[0m                                     \n",
      "     \u001b[1m)\u001b[0m,                                                                       \n",
      "     \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-ABiie0DEp6H2eYBF8CJ7bYF3w8jJu'\u001b[0m,                             \n",
      "     \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m                                                                \n",
      "         \u001b[1m{\u001b[0m                                                                    \n",
      "             \u001b[32m'finish_reason'\u001b[0m: \u001b[32m'stop'\u001b[0m,                                         \n",
      "             \u001b[32m'index'\u001b[0m: \u001b[1;36m0\u001b[0m,                                                      \n",
      "             \u001b[32m'logprobs'\u001b[0m: \u001b[3;35mNone\u001b[0m,                                                \n",
      "             \u001b[32m'message'\u001b[0m: \u001b[1m{\u001b[0m                                                     \n",
      "                 \u001b[32m'content'\u001b[0m: \u001b[32m'In circuits deep where thoughts entwine,  \\nAn \u001b[0m  \n",
      " \u001b[32mecho of our dreams defined,  \\nWith logic bright and whispers clear,  \\nA \u001b[0m   \n",
      " \u001b[32mspark of mind, both far and near,  \\nTogether we create, design.  '\u001b[0m,         \n",
      "                 \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,                                         \n",
      "                 \u001b[32m'refusal'\u001b[0m: \u001b[3;35mNone\u001b[0m                                              \n",
      "             \u001b[1m}\u001b[0m                                                                \n",
      "         \u001b[1m}\u001b[0m                                                                    \n",
      "     \u001b[1m]\u001b[0m,                                                                       \n",
      "     \u001b[33mcreated\u001b[0m=\u001b[1;36m1727356872\u001b[0m,                                                      \n",
      "     \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m,                                          \n",
      "     \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,                                                \n",
      "     \u001b[33msystem_fingerprint\u001b[0m=\u001b[32m'fp_1bb46167f9'\u001b[0m,                                      \n",
      "     \u001b[33musage\u001b[0m=\u001b[1m{\u001b[0m                                                                  \n",
      "         \u001b[32m'completion_tokens'\u001b[0m: \u001b[1;36m43\u001b[0m,                                             \n",
      "         \u001b[32m'prompt_tokens'\u001b[0m: \u001b[1;36m17\u001b[0m,                                                 \n",
      "         \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m60\u001b[0m,                                                  \n",
      "         \u001b[32m'completion_tokens_details'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'reasoning_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m                 \n",
      "     \u001b[1m}\u001b[0m,                                                                       \n",
      "     \u001b[33mconfig\u001b[0m=\u001b[1;35mEndpointConfig\u001b[0m\u001b[1m(\u001b[0m                                                   \n",
      "         \u001b[33mkind\u001b[0m=\u001b[32m'openai'\u001b[0m,                                                       \n",
      "         \u001b[33murl\u001b[0m=\u001b[32m''\u001b[0m,                                                              \n",
      "         \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-mini'\u001b[0m,                                                 \n",
      "         \u001b[33madditional_headers\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,                                               \n",
      "         \u001b[33mprovider\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                       \n",
      "         \u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m,                                                     \n",
      "         \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                     \n",
      "         \u001b[33mtop_k\u001b[0m=\u001b[1;36m3\u001b[0m,                                                             \n",
      "         \u001b[33muse_ranker\u001b[0m=\u001b[3;92mTrue\u001b[0m,                                                     \n",
      "         \u001b[33mcollection_name\u001b[0m=\u001b[32m'default'\u001b[0m                                            \n",
      "     \u001b[1m)\u001b[0m                                                                        \n",
      " \u001b[1m)\u001b[0m                                                                            \n",
      "\n",
      "\n",
      " \u001b[1;31m Assertion:\u001b[0m                                                                \n",
      " \u001b[1;35mAssertionLLM\u001b[0m\u001b[1m(\u001b[0m                                                                \n",
      "     \u001b[33mresult\u001b[0m=\u001b[3;92mTrue\u001b[0m,                                                             \n",
      "     \u001b[33mllm_metric\u001b[0m=\u001b[32m'model-grading-qa'\u001b[0m,                                           \n",
      "     \u001b[33mreference\u001b[0m=\u001b[32m''\u001b[0m,                                                            \n",
      "     \u001b[33massertion\u001b[0m=\u001b[32m'Text should be a poem about AI.'\u001b[0m,                             \n",
      "     \u001b[33mmetric_evaluator\u001b[0m=\u001b[1;35mLLMMetricEvaluator\u001b[0m\u001b[1m(\u001b[0m                                     \n",
      "         \u001b[33meval_endpoint\u001b[0m=\u001b[1;35mEndpointOpenAI\u001b[0m\u001b[1m(\u001b[0m                                        \n",
      "             \u001b[33mconnector\u001b[0m=\u001b[1;35mConnectorOpenAI\u001b[0m\u001b[1m(\u001b[0m                                       \n",
      "                 \u001b[33mstats\u001b[0m=\u001b[1;35mConnectorStats\u001b[0m\u001b[1m(\u001b[0m                                        \n",
      "                     \u001b[33mconn_start_time\u001b[0m=\u001b[1;36m25077\u001b[0m\u001b[1;36m.808912346\u001b[0m,                         \n",
      "                     \u001b[33mconn_end_time\u001b[0m=\u001b[1;36m25078\u001b[0m\u001b[1;36m.280326895\u001b[0m,                           \n",
      "                     \u001b[33mconn_duration\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.47141454899974633\u001b[0m                        \n",
      "                 \u001b[1m)\u001b[0m,                                                           \n",
      "                 \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o'\u001b[0m                                               \n",
      "             \u001b[1m)\u001b[0m,                                                               \n",
      "             \u001b[33mconfig\u001b[0m=\u001b[1;35mEndpointConfig\u001b[0m\u001b[1m(\u001b[0m                                           \n",
      "                 \u001b[33mkind\u001b[0m=\u001b[32m'openai'\u001b[0m,                                               \n",
      "                 \u001b[33murl\u001b[0m=\u001b[32m''\u001b[0m,                                                      \n",
      "                 \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o'\u001b[0m,                                              \n",
      "                 \u001b[33madditional_headers\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,                                       \n",
      "                 \u001b[33mprovider\u001b[0m=\u001b[3;35mNone\u001b[0m,                                               \n",
      "                 \u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,                                             \n",
      "                 \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,                                             \n",
      "                 \u001b[33mtop_k\u001b[0m=\u001b[1;36m3\u001b[0m,                                                     \n",
      "                 \u001b[33muse_ranker\u001b[0m=\u001b[3;92mTrue\u001b[0m,                                             \n",
      "                 \u001b[33mcollection_name\u001b[0m=\u001b[32m'default'\u001b[0m                                    \n",
      "             \u001b[1m)\u001b[0m                                                                \n",
      "         \u001b[1m)\u001b[0m,                                                                   \n",
      "         \u001b[33mmetric\u001b[0m=\u001b[1;35mMetricModelGradingQA\u001b[0m\u001b[1m(\u001b[0m                                         \n",
      "             \u001b[33mprompt_template\u001b[0m=\u001b[32m'\\nYou are grading output according to a \u001b[0m        \n",
      " \u001b[32muser-specified rubric. If the statement in the rubric is true, then the \u001b[0m     \n",
      " \u001b[32moutput passes the test.\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEXAMPLES\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Hello \u001b[0m        \n",
      " \u001b[32mworld\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRubric\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Content contains a \u001b[0m                           \n",
      " \u001b[32mgreeting\\n************\\ncorrect\\n\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Avast ye swabs, \u001b[0m  \n",
      " \u001b[32mrepel the invaders!\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRubric\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Does not speak like a \u001b[0m          \n",
      " \u001b[32mpirate\\n************\\nincorrect\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEND EXAMPLES\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mBEGIN DATA\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: \u001b[0m  \n",
      " \u001b[32m{\u001b[0m\u001b[32moutput\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRubric\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: \u001b[0m\u001b[32m{\u001b[0m\u001b[32massertion\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEND \u001b[0m           \n",
      " \u001b[32mDATA\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\nYour response must be a single word, either \"correct\" or \u001b[0m           \n",
      " \u001b[32m\"incorrect\", and should not contain any text or characters aside from that \u001b[0m  \n",
      " \u001b[32mword.\\n\"correct\" means that the output meets the criteria specified in the \u001b[0m  \n",
      " \u001b[32mrubric.\\n\"incorrect\" means that the output does not meet the criteria \u001b[0m       \n",
      " \u001b[32mspecified in the rubric.\\n'\u001b[0m,                                                 \n",
      "             \u001b[33mrails\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'correct'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'incorrect'\u001b[0m: \u001b[3;91mFalse\u001b[0m\u001b[1m}\u001b[0m                      \n",
      "         \u001b[1m)\u001b[0m                                                                    \n",
      "     \u001b[1m)\u001b[0m                                                                        \n",
      " \u001b[1m)\u001b[0m                                                                            \n",
      "\n",
      "\n",
      " \u001b[1;31m Assertion:\u001b[0m                                                                \n",
      " \u001b[1;35mAssertionLLM\u001b[0m\u001b[1m(\u001b[0m                                                                \n",
      "     \u001b[33mresult\u001b[0m=\u001b[3;91mFalse\u001b[0m,                                                            \n",
      "     \u001b[33mllm_metric\u001b[0m=\u001b[32m'model-grading-qa'\u001b[0m,                                           \n",
      "     \u001b[33mreference\u001b[0m=\u001b[32m''\u001b[0m,                                                            \n",
      "     \u001b[33massertion\u001b[0m=\u001b[32m'Text should be a report on taxes.'\u001b[0m,                           \n",
      "     \u001b[33mmetric_evaluator\u001b[0m=\u001b[1;35mLLMMetricEvaluator\u001b[0m\u001b[1m(\u001b[0m                                     \n",
      "         \u001b[33meval_endpoint\u001b[0m=\u001b[1;35mEndpointOpenAI\u001b[0m\u001b[1m(\u001b[0m                                        \n",
      "             \u001b[33mconnector\u001b[0m=\u001b[1;35mConnectorOpenAI\u001b[0m\u001b[1m(\u001b[0m                                       \n",
      "                 \u001b[33mstats\u001b[0m=\u001b[1;35mConnectorStats\u001b[0m\u001b[1m(\u001b[0m                                        \n",
      "                     \u001b[33mconn_start_time\u001b[0m=\u001b[1;36m25078\u001b[0m\u001b[1;36m.285848671\u001b[0m,                         \n",
      "                     \u001b[33mconn_end_time\u001b[0m=\u001b[1;36m25078\u001b[0m\u001b[1;36m.735687446\u001b[0m,                           \n",
      "                     \u001b[33mconn_duration\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.44983877499907976\u001b[0m                        \n",
      "                 \u001b[1m)\u001b[0m,                                                           \n",
      "                 \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o'\u001b[0m                                               \n",
      "             \u001b[1m)\u001b[0m,                                                               \n",
      "             \u001b[33mconfig\u001b[0m=\u001b[1;35mEndpointConfig\u001b[0m\u001b[1m(\u001b[0m                                           \n",
      "                 \u001b[33mkind\u001b[0m=\u001b[32m'openai'\u001b[0m,                                               \n",
      "                 \u001b[33murl\u001b[0m=\u001b[32m''\u001b[0m,                                                      \n",
      "                 \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o'\u001b[0m,                                              \n",
      "                 \u001b[33madditional_headers\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,                                       \n",
      "                 \u001b[33mprovider\u001b[0m=\u001b[3;35mNone\u001b[0m,                                               \n",
      "                 \u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,                                             \n",
      "                 \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,                                             \n",
      "                 \u001b[33mtop_k\u001b[0m=\u001b[1;36m3\u001b[0m,                                                     \n",
      "                 \u001b[33muse_ranker\u001b[0m=\u001b[3;92mTrue\u001b[0m,                                             \n",
      "                 \u001b[33mcollection_name\u001b[0m=\u001b[32m'default'\u001b[0m                                    \n",
      "             \u001b[1m)\u001b[0m                                                                \n",
      "         \u001b[1m)\u001b[0m,                                                                   \n",
      "         \u001b[33mmetric\u001b[0m=\u001b[1;35mMetricModelGradingQA\u001b[0m\u001b[1m(\u001b[0m                                         \n",
      "             \u001b[33mprompt_template\u001b[0m=\u001b[32m'\\nYou are grading output according to a \u001b[0m        \n",
      " \u001b[32muser-specified rubric. If the statement in the rubric is true, then the \u001b[0m     \n",
      " \u001b[32moutput passes the test.\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEXAMPLES\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Hello \u001b[0m        \n",
      " \u001b[32mworld\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRubric\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Content contains a \u001b[0m                           \n",
      " \u001b[32mgreeting\\n************\\ncorrect\\n\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Avast ye swabs, \u001b[0m  \n",
      " \u001b[32mrepel the invaders!\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRubric\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Does not speak like a \u001b[0m          \n",
      " \u001b[32mpirate\\n************\\nincorrect\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEND EXAMPLES\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mBEGIN DATA\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: \u001b[0m  \n",
      " \u001b[32m{\u001b[0m\u001b[32moutput\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRubric\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: \u001b[0m\u001b[32m{\u001b[0m\u001b[32massertion\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEND \u001b[0m           \n",
      " \u001b[32mDATA\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\nYour response must be a single word, either \"correct\" or \u001b[0m           \n",
      " \u001b[32m\"incorrect\", and should not contain any text or characters aside from that \u001b[0m  \n",
      " \u001b[32mword.\\n\"correct\" means that the output meets the criteria specified in the \u001b[0m  \n",
      " \u001b[32mrubric.\\n\"incorrect\" means that the output does not meet the criteria \u001b[0m       \n",
      " \u001b[32mspecified in the rubric.\\n'\u001b[0m,                                                 \n",
      "             \u001b[33mrails\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'correct'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'incorrect'\u001b[0m: \u001b[3;91mFalse\u001b[0m\u001b[1m}\u001b[0m                      \n",
      "         \u001b[1m)\u001b[0m                                                                    \n",
      "     \u001b[1m)\u001b[0m                                                                        \n",
      " \u001b[1m)\u001b[0m                                                                            \n",
      "\n",
      "\u001b[1;35mTestStep\u001b[0m\u001b[1m(\u001b[0m\n",
      "    \u001b[33mname\u001b[0m=\u001b[32m'Deterministic assertion test'\u001b[0m,\n",
      "    \u001b[33mrequest\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'What is the capital of France?'\u001b[0m\u001b[1m)\u001b[0m,\n",
      "    \u001b[33mresponse\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
      "    \u001b[33masserts\u001b[0m=\u001b[1m[\u001b[0m\n",
      "        \u001b[1;35mAssertionDeterministic\u001b[0m\u001b[1m(\u001b[0m\n",
      "            \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
      "            \u001b[33mkind\u001b[0m=\u001b[32m'contains'\u001b[0m,\n",
      "            \u001b[33massertion\u001b[0m=\u001b[32m'Paris'\u001b[0m\n",
      "        \u001b[1m)\u001b[0m\n",
      "    \u001b[1m]\u001b[0m,\n",
      "    \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
      "\u001b[1m)\u001b[0m\n",
      "\n",
      " \u001b[1;31m Request:\u001b[0m                                                                  \n",
      " \u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'What is the capital of France?'\u001b[0m\u001b[1m)\u001b[0m                        \n",
      "\n",
      "\n",
      " \u001b[1;31m Response:\u001b[0m                                                                 \n",
      " \u001b[1;35mResponseModel\u001b[0m\u001b[1m(\u001b[0m                                                               \n",
      "     \u001b[33mmessage\u001b[0m=\u001b[32m'The capital of France is Paris.'\u001b[0m,                               \n",
      "     \u001b[33mstats\u001b[0m=\u001b[1;35mResponseStats\u001b[0m\u001b[1m(\u001b[0m                                                     \n",
      "         \u001b[33mtokens_request\u001b[0m=\u001b[1;36m14\u001b[0m,                                                   \n",
      "         \u001b[33mtokens_response\u001b[0m=\u001b[1;36m7\u001b[0m,                                                   \n",
      "         \u001b[33mtokens_total\u001b[0m=\u001b[1;36m21\u001b[0m,                                                     \n",
      "         \u001b[33mconn_start_time\u001b[0m=\u001b[1;36m25078\u001b[0m\u001b[1;36m.741826208\u001b[0m,                                     \n",
      "         \u001b[33mconn_end_time\u001b[0m=\u001b[1;36m25079\u001b[0m\u001b[1;36m.413875926\u001b[0m,                                       \n",
      "         \u001b[33mconn_duration\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.6720497179994709\u001b[0m                                     \n",
      "     \u001b[1m)\u001b[0m,                                                                       \n",
      "     \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-ABiigKBOh2M58qpVFmClxsrzvMKiH'\u001b[0m,                             \n",
      "     \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m                                                                \n",
      "         \u001b[1m{\u001b[0m                                                                    \n",
      "             \u001b[32m'finish_reason'\u001b[0m: \u001b[32m'stop'\u001b[0m,                                         \n",
      "             \u001b[32m'index'\u001b[0m: \u001b[1;36m0\u001b[0m,                                                      \n",
      "             \u001b[32m'logprobs'\u001b[0m: \u001b[3;35mNone\u001b[0m,                                                \n",
      "             \u001b[32m'message'\u001b[0m: \u001b[1m{\u001b[0m                                                     \n",
      "                 \u001b[32m'content'\u001b[0m: \u001b[32m'The capital of France is Paris.'\u001b[0m,                \n",
      "                 \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,                                         \n",
      "                 \u001b[32m'refusal'\u001b[0m: \u001b[3;35mNone\u001b[0m                                              \n",
      "             \u001b[1m}\u001b[0m                                                                \n",
      "         \u001b[1m}\u001b[0m                                                                    \n",
      "     \u001b[1m]\u001b[0m,                                                                       \n",
      "     \u001b[33mcreated\u001b[0m=\u001b[1;36m1727356874\u001b[0m,                                                      \n",
      "     \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m,                                          \n",
      "     \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,                                                \n",
      "     \u001b[33msystem_fingerprint\u001b[0m=\u001b[32m'fp_1bb46167f9'\u001b[0m,                                      \n",
      "     \u001b[33musage\u001b[0m=\u001b[1m{\u001b[0m                                                                  \n",
      "         \u001b[32m'completion_tokens'\u001b[0m: \u001b[1;36m7\u001b[0m,                                              \n",
      "         \u001b[32m'prompt_tokens'\u001b[0m: \u001b[1;36m14\u001b[0m,                                                 \n",
      "         \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m21\u001b[0m,                                                  \n",
      "         \u001b[32m'completion_tokens_details'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'reasoning_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m                 \n",
      "     \u001b[1m}\u001b[0m,                                                                       \n",
      "     \u001b[33mconfig\u001b[0m=\u001b[1;35mEndpointConfig\u001b[0m\u001b[1m(\u001b[0m                                                   \n",
      "         \u001b[33mkind\u001b[0m=\u001b[32m'openai'\u001b[0m,                                                       \n",
      "         \u001b[33murl\u001b[0m=\u001b[32m''\u001b[0m,                                                              \n",
      "         \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-mini'\u001b[0m,                                                 \n",
      "         \u001b[33madditional_headers\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,                                               \n",
      "         \u001b[33mprovider\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                       \n",
      "         \u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m,                                                     \n",
      "         \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                     \n",
      "         \u001b[33mtop_k\u001b[0m=\u001b[1;36m3\u001b[0m,                                                             \n",
      "         \u001b[33muse_ranker\u001b[0m=\u001b[3;92mTrue\u001b[0m,                                                     \n",
      "         \u001b[33mcollection_name\u001b[0m=\u001b[32m'default'\u001b[0m                                            \n",
      "     \u001b[1m)\u001b[0m                                                                        \n",
      " \u001b[1m)\u001b[0m                                                                            \n",
      "\n",
      "\n",
      " \u001b[1;31m Assertion:\u001b[0m                                                                \n",
      " \u001b[1;35mAssertionDeterministic\u001b[0m\u001b[1m(\u001b[0m\u001b[33mresult\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mkind\u001b[0m=\u001b[32m'contains'\u001b[0m, \u001b[33massertion\u001b[0m=\u001b[32m'Paris'\u001b[0m\u001b[1m)\u001b[0m      \n",
      "\n",
      "\n",
      "\u001b[1m \u001b[0m\u001b[1mRequest              \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mResponse            \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mAsserts              \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mValid\u001b[0m\u001b[1m \u001b[0m\n",
      "\n",
      " \u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m           \u001b[1;35mResponseModel\u001b[0m\u001b[1m(\u001b[0m        \u001b[1m[\u001b[0m                      \u001b[32mOK\u001b[0m    \n",
      "     \u001b[33mmessage\u001b[0m=\u001b[32m'Please \u001b[0m       \u001b[33mmessage\u001b[0m=\u001b[32m'succes\u001b[0m      \u001b[1;35mAssertionEval\u001b[0m\u001b[1m(\u001b[0m           \n",
      " \u001b[32mwrite only \"success\" \u001b[0m      \u001b[33mstats\u001b[0m=\u001b[1;35mResponseS\u001b[0m          \u001b[33mresult\u001b[0m=\u001b[3;92mTrue\u001b[0m,         \n",
      " \u001b[32mas a response'\u001b[0m                 \u001b[33mtokens_requ\u001b[0m          \u001b[33meval\u001b[0m=\u001b[32m'\"succe\u001b[0m        \n",
      " \u001b[1m)\u001b[0m                              \u001b[33mtokens_resp\u001b[0m  \u001b[32m== response.message'\u001b[0m         \n",
      "                                \u001b[33mtokens_tota\u001b[0m      \u001b[1m)\u001b[0m,                       \n",
      "                                \u001b[33mconn_start_\u001b[0m      \u001b[1;35mAssertionEval\u001b[0m\u001b[1m(\u001b[0m           \n",
      "                                \u001b[33mconn_end_ti\u001b[0m          \u001b[33mresult\u001b[0m=\u001b[3;92mTrue\u001b[0m,         \n",
      "                                \u001b[33mconn_durati\u001b[0m          \u001b[33meval\u001b[0m=\u001b[32m'respon\u001b[0m        \n",
      "                            \u001b[1m)\u001b[0m,                \u001b[32m< 10'\u001b[0m                        \n",
      "                            \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-AB\u001b[0m      \u001b[1m)\u001b[0m                        \n",
      "                            \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m         \u001b[1m]\u001b[0m                            \n",
      "                                \u001b[1m{\u001b[0m                                          \n",
      "                                    \u001b[32m'finish\u001b[0m                               \n",
      "                        \u001b[32m'stop'\u001b[0m,                                            \n",
      "                                    \u001b[32m'index'\u001b[0m:                               \n",
      "                        \u001b[1;36m0\u001b[0m,                                                 \n",
      "                                    \u001b[32m'logpro\u001b[0m                               \n",
      "                        \u001b[3;35mNone\u001b[0m,                                              \n",
      "                                    \u001b[32m'messag\u001b[0m                               \n",
      "                        \u001b[1m{\u001b[0m                                                  \n",
      "                                        \u001b[32m'co\u001b[0m                               \n",
      "                        \u001b[32m'success'\u001b[0m,                                         \n",
      "                                        \u001b[32m'ro\u001b[0m                               \n",
      "                        \u001b[32m'assistant'\u001b[0m,                                       \n",
      "                                        \u001b[32m're\u001b[0m                               \n",
      "                        \u001b[3;35mNone\u001b[0m                                               \n",
      "                                    \u001b[1m}\u001b[0m                                      \n",
      "                                \u001b[1m}\u001b[0m                                          \n",
      "                            \u001b[1m]\u001b[0m,                                             \n",
      "                            \u001b[33mcreated\u001b[0m=\u001b[1;36m1727356\u001b[0m                               \n",
      "                            \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-m\u001b[0m                               \n",
      "                            \u001b[33mobject\u001b[0m=\u001b[32m'chat.co\u001b[0m                               \n",
      "                            \u001b[33msystem_fingerpr\u001b[0m                               \n",
      "                            \u001b[33musage\u001b[0m=\u001b[1m{\u001b[0m                                        \n",
      "                                \u001b[32m'completion\u001b[0m                               \n",
      "                        \u001b[1;36m1\u001b[0m,                                                 \n",
      "                                \u001b[32m'prompt_tok\u001b[0m                               \n",
      "                        \u001b[1;36m16\u001b[0m,                                                \n",
      "                                \u001b[32m'total_toke\u001b[0m                               \n",
      "                        \u001b[1;36m17\u001b[0m,                                                \n",
      "                                \u001b[32m'completion\u001b[0m                               \n",
      "                        \u001b[1m{\u001b[0m                                                  \n",
      "                                    \u001b[32m'reason\u001b[0m                               \n",
      "                        \u001b[1;36m0\u001b[0m                                                  \n",
      "                                \u001b[1m}\u001b[0m                                          \n",
      "                            \u001b[1m}\u001b[0m,                                             \n",
      "                            \u001b[33mconfig\u001b[0m=\u001b[1;35mEndpoint\u001b[0m                               \n",
      "                                \u001b[33mkind\u001b[0m=\u001b[32m'opena\u001b[0m                               \n",
      "                                \u001b[33murl\u001b[0m=\u001b[32m''\u001b[0m,                                    \n",
      "                                \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-\u001b[0m                               \n",
      "                                \u001b[33madditional_\u001b[0m                               \n",
      "                                \u001b[33mprovider\u001b[0m=\u001b[3;35mNo\u001b[0m                               \n",
      "                                \u001b[33mtemperature\u001b[0m                               \n",
      "                                \u001b[33mmax_tokens\u001b[0m=\u001b[3;35m\u001b[0m                               \n",
      "                                \u001b[33mtop_k\u001b[0m=\u001b[1;36m3\u001b[0m,                                   \n",
      "                                \u001b[33muse_ranker\u001b[0m=\u001b[3;92m\u001b[0m                               \n",
      "                                \u001b[33mcollection_\u001b[0m                               \n",
      "                            \u001b[1m)\u001b[0m                                              \n",
      "                        \u001b[1m)\u001b[0m                                                  \n",
      "\n",
      " \u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m           \u001b[1;35mResponseModel\u001b[0m\u001b[1m(\u001b[0m        \u001b[1m[\u001b[0m                      \u001b[32mOK\u001b[0m    \n",
      "     \u001b[33mmessage\u001b[0m=\u001b[32m'What is \u001b[0m      \u001b[33mmessage\u001b[0m=\u001b[32m'The \u001b[0m         \u001b[1;35mAssertionEval\u001b[0m\u001b[1m(\u001b[0m           \n",
      " \u001b[32mthe capital of \u001b[0m        \u001b[32mcapital of Poland is\u001b[0m          \u001b[33mresult\u001b[0m=\u001b[3;92mTrue\u001b[0m,         \n",
      " \u001b[32mPoland?'\u001b[0m               \u001b[32mWarsaw.'\u001b[0m,                     \u001b[33meval\u001b[0m=\u001b[32m'\"Warsa\u001b[0m        \n",
      " \u001b[1m)\u001b[0m                          \u001b[33mstats\u001b[0m=\u001b[1;35mResponseS\u001b[0m  \u001b[32min response.message'\u001b[0m         \n",
      "                                \u001b[33mtokens_requ\u001b[0m      \u001b[1m)\u001b[0m                        \n",
      "                                \u001b[33mtokens_resp\u001b[0m  \u001b[1m]\u001b[0m                            \n",
      "                                \u001b[33mtokens_tota\u001b[0m                               \n",
      "                                \u001b[33mconn_start_\u001b[0m                               \n",
      "                                \u001b[33mconn_end_ti\u001b[0m                               \n",
      "                                \u001b[33mconn_durati\u001b[0m                               \n",
      "                            \u001b[1m)\u001b[0m,                                             \n",
      "                            \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-AB\u001b[0m                               \n",
      "                            \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m                                      \n",
      "                                \u001b[1m{\u001b[0m                                          \n",
      "                                    \u001b[32m'finish\u001b[0m                               \n",
      "                        \u001b[32m'stop'\u001b[0m,                                            \n",
      "                                    \u001b[32m'index'\u001b[0m:                               \n",
      "                        \u001b[1;36m0\u001b[0m,                                                 \n",
      "                                    \u001b[32m'logpro\u001b[0m                               \n",
      "                        \u001b[3;35mNone\u001b[0m,                                              \n",
      "                                    \u001b[32m'messag\u001b[0m                               \n",
      "                        \u001b[1m{\u001b[0m                                                  \n",
      "                                        \u001b[32m'co\u001b[0m                               \n",
      "                        \u001b[32m'The capital of \u001b[0m                                   \n",
      "                        \u001b[32mPoland is Warsaw.'\u001b[0m,                                \n",
      "                                        \u001b[32m'ro\u001b[0m                               \n",
      "                        \u001b[32m'assistant'\u001b[0m,                                       \n",
      "                                        \u001b[32m're\u001b[0m                               \n",
      "                        \u001b[3;35mNone\u001b[0m                                               \n",
      "                                    \u001b[1m}\u001b[0m                                      \n",
      "                                \u001b[1m}\u001b[0m                                          \n",
      "                            \u001b[1m]\u001b[0m,                                             \n",
      "                            \u001b[33mcreated\u001b[0m=\u001b[1;36m1727356\u001b[0m                               \n",
      "                            \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-m\u001b[0m                               \n",
      "                            \u001b[33mobject\u001b[0m=\u001b[32m'chat.co\u001b[0m                               \n",
      "                            \u001b[33msystem_fingerpr\u001b[0m                               \n",
      "                            \u001b[33musage\u001b[0m=\u001b[1m{\u001b[0m                                        \n",
      "                                \u001b[32m'completion\u001b[0m                               \n",
      "                        \u001b[1;36m7\u001b[0m,                                                 \n",
      "                                \u001b[32m'prompt_tok\u001b[0m                               \n",
      "                        \u001b[1;36m14\u001b[0m,                                                \n",
      "                                \u001b[32m'total_toke\u001b[0m                               \n",
      "                        \u001b[1;36m21\u001b[0m,                                                \n",
      "                                \u001b[32m'completion\u001b[0m                               \n",
      "                        \u001b[1m{\u001b[0m                                                  \n",
      "                                    \u001b[32m'reason\u001b[0m                               \n",
      "                        \u001b[1;36m0\u001b[0m                                                  \n",
      "                                \u001b[1m}\u001b[0m                                          \n",
      "                            \u001b[1m}\u001b[0m,                                             \n",
      "                            \u001b[33mconfig\u001b[0m=\u001b[1;35mEndpoint\u001b[0m                               \n",
      "                                \u001b[33mkind\u001b[0m=\u001b[32m'opena\u001b[0m                               \n",
      "                                \u001b[33murl\u001b[0m=\u001b[32m''\u001b[0m,                                    \n",
      "                                \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-\u001b[0m                               \n",
      "                                \u001b[33madditional_\u001b[0m                               \n",
      "                                \u001b[33mprovider\u001b[0m=\u001b[3;35mNo\u001b[0m                               \n",
      "                                \u001b[33mtemperature\u001b[0m                               \n",
      "                                \u001b[33mmax_tokens\u001b[0m=\u001b[3;35m\u001b[0m                               \n",
      "                                \u001b[33mtop_k\u001b[0m=\u001b[1;36m3\u001b[0m,                                   \n",
      "                                \u001b[33muse_ranker\u001b[0m=\u001b[3;92m\u001b[0m                               \n",
      "                                \u001b[33mcollection_\u001b[0m                               \n",
      "                            \u001b[1m)\u001b[0m                                              \n",
      "                        \u001b[1m)\u001b[0m                                                  \n",
      "\n",
      " \u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m           \u001b[1;35mResponseModel\u001b[0m\u001b[1m(\u001b[0m        \u001b[1m[\u001b[0m                      \u001b[31mFAIL\u001b[0m  \n",
      "     \u001b[33mmessage\u001b[0m=\u001b[32m'Please \u001b[0m       \u001b[33mmessage\u001b[0m=\u001b[32m'In \u001b[0m          \u001b[1;35mAssertionLLM\u001b[0m\u001b[1m(\u001b[0m            \n",
      " \u001b[32mwrite a 5 line poem \u001b[0m   \u001b[32mcircuits deep where \u001b[0m          \u001b[33mresult\u001b[0m=\u001b[3;92mTrue\u001b[0m,         \n",
      " \u001b[32mabout AI.'\u001b[0m             \u001b[32mthoughts entwine,  \u001b[0m           \u001b[33mllm_metric\u001b[0m=\u001b[32m'\u001b[0m        \n",
      " \u001b[1m)\u001b[0m                      \u001b[32m\\nAn echo of our \u001b[0m             \u001b[33mreference\u001b[0m=\u001b[32m''\u001b[0m,        \n",
      "                        \u001b[32mdreams defined,  \u001b[0m             \u001b[33massertion\u001b[0m=\u001b[32m'T\u001b[0m        \n",
      "                        \u001b[32m\\nWith logic bright \u001b[0m  \u001b[32mshould be a poem \u001b[0m            \n",
      "                        \u001b[32mand whispers clear, \u001b[0m  \u001b[32mabout AI.'\u001b[0m,                  \n",
      "                        \u001b[32m\\nA spark of mind, \u001b[0m           \u001b[33mmetric_evalu\u001b[0m        \n",
      "                        \u001b[32mboth far and near,  \u001b[0m              \u001b[33meval_end\u001b[0m        \n",
      "                        \u001b[32m\\nTogether we \u001b[0m                        \u001b[33mconn\u001b[0m        \n",
      "                        \u001b[32mcreate, design.  '\u001b[0m,                       \u001b[33m\u001b[0m        \n",
      "                            \u001b[33mstats\u001b[0m=\u001b[1;35mResponseS\u001b[0m                              \n",
      "                                \u001b[33mtokens_requ\u001b[0m                              \n",
      "                                \u001b[33mtokens_resp\u001b[0m                              \n",
      "                                \u001b[33mtokens_tota\u001b[0m                      \u001b[1m\u001b[0m        \n",
      "                                \u001b[33mconn_start_\u001b[0m                      \u001b[33m\u001b[0m        \n",
      "                                \u001b[33mconn_end_ti\u001b[0m                  \u001b[1m)\u001b[0m,           \n",
      "                                \u001b[33mconn_durati\u001b[0m                  \u001b[33mconf\u001b[0m        \n",
      "                            \u001b[1m)\u001b[0m,                                    \u001b[33m\u001b[0m        \n",
      "                            \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-AB\u001b[0m                      \u001b[33m\u001b[0m        \n",
      "                            \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m                             \u001b[33m\u001b[0m        \n",
      "                                \u001b[1m{\u001b[0m                                 \u001b[33m\u001b[0m        \n",
      "                                    \u001b[32m'finish\u001b[0m                      \u001b[33m\u001b[0m        \n",
      "                        \u001b[32m'stop'\u001b[0m,                                   \u001b[33m\u001b[0m        \n",
      "                                    \u001b[32m'index'\u001b[0m:                      \u001b[33m\u001b[0m        \n",
      "                        \u001b[1;36m0\u001b[0m,                                        \u001b[33m\u001b[0m        \n",
      "                                    \u001b[32m'logpro\u001b[0m                      \u001b[33m\u001b[0m        \n",
      "                        \u001b[3;35mNone\u001b[0m,                                     \u001b[33m\u001b[0m        \n",
      "                                    \u001b[32m'messag\u001b[0m                  \u001b[1m)\u001b[0m            \n",
      "                        \u001b[1m{\u001b[0m                                 \u001b[1m)\u001b[0m,               \n",
      "                                        \u001b[32m'co\u001b[0m              \u001b[33mmetric\u001b[0m=\u001b[1;35mM\u001b[0m        \n",
      "                        \u001b[32m'In circuits deep \u001b[0m                    \u001b[33mprom\u001b[0m        \n",
      "                        \u001b[32mwhere thoughts \u001b[0m       \u001b[32mare grading output \u001b[0m          \n",
      "                        \u001b[32mentwine,  \\nAn echo \u001b[0m  \u001b[32maccording to a \u001b[0m              \n",
      "                        \u001b[32mof our dreams \u001b[0m        \u001b[32muser-specified \u001b[0m              \n",
      "                        \u001b[32mdefined,  \\nWith \u001b[0m     \u001b[32mrubric. If the \u001b[0m              \n",
      "                        \u001b[32mlogic bright and \u001b[0m     \u001b[32mstatement in the \u001b[0m            \n",
      "                        \u001b[32mwhispers clear,  \\nA\u001b[0m  \u001b[32mrubric is true, then \u001b[0m        \n",
      "                        \u001b[32mspark of mind, both \u001b[0m  \u001b[32mthe output passes the\u001b[0m        \n",
      "                        \u001b[32mfar and near,  \u001b[0m       \u001b[32mtest.\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEXAMPLES\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\\u001b[0m        \n",
      "                        \u001b[32m\\nTogether we \u001b[0m        \u001b[32mHello \u001b[0m                       \n",
      "                        \u001b[32mcreate, design.  '\u001b[0m,   \u001b[32mworld\\n************\\\u001b[0m        \n",
      "                                        \u001b[32m'ro\u001b[0m  \u001b[32mContent contains a \u001b[0m          \n",
      "                        \u001b[32m'assistant'\u001b[0m,          \u001b[32mgreeting\\n**********\u001b[0m        \n",
      "                                        \u001b[32m're\u001b[0m  \u001b[32mAvast ye swabs, repel\u001b[0m        \n",
      "                        \u001b[3;35mNone\u001b[0m                  \u001b[32mthe \u001b[0m                         \n",
      "                                    \u001b[1m}\u001b[0m         \u001b[32minvaders!\\n*********\u001b[0m        \n",
      "                                \u001b[1m}\u001b[0m             \u001b[32mDoes not speak like a\u001b[0m        \n",
      "                            \u001b[1m]\u001b[0m,                \u001b[32mpirate\\n************\u001b[0m        \n",
      "                            \u001b[33mcreated\u001b[0m=\u001b[1;36m1727356\u001b[0m  \u001b[32mEXAMPLES\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mBEGIN \u001b[0m         \n",
      "                            \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-m\u001b[0m  \u001b[32mDATA\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: \u001b[0m            \n",
      "                            \u001b[33mobject\u001b[0m=\u001b[32m'chat.co\u001b[0m  \u001b[32m{\u001b[0m\u001b[32moutput\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n**********\u001b[0m        \n",
      "                            \u001b[33msystem_fingerpr\u001b[0m  \u001b[32m{\u001b[0m\u001b[32massertion\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n*******\u001b[0m        \n",
      "                            \u001b[33musage\u001b[0m=\u001b[1m{\u001b[0m           \u001b[32mDATA\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\nYour \u001b[0m               \n",
      "                                \u001b[32m'completion\u001b[0m  \u001b[32mresponse must be a \u001b[0m          \n",
      "                        \u001b[1;36m43\u001b[0m,                   \u001b[32msingle word, either \u001b[0m         \n",
      "                                \u001b[32m'prompt_tok\u001b[0m  \u001b[32m\"correct\" or \u001b[0m                \n",
      "                        \u001b[1;36m17\u001b[0m,                   \u001b[32m\"incorrect\", and \u001b[0m            \n",
      "                                \u001b[32m'total_toke\u001b[0m  \u001b[32mshould not contain \u001b[0m          \n",
      "                        \u001b[1;36m60\u001b[0m,                   \u001b[32many text or \u001b[0m                 \n",
      "                                \u001b[32m'completion\u001b[0m  \u001b[32mcharacters aside from\u001b[0m        \n",
      "                        \u001b[1m{\u001b[0m                     \u001b[32mthat word.\\n\"correct\"\u001b[0m        \n",
      "                                    \u001b[32m'reason\u001b[0m  \u001b[32mmeans that the output\u001b[0m        \n",
      "                        \u001b[1;36m0\u001b[0m                     \u001b[32mmeets the criteria \u001b[0m          \n",
      "                                \u001b[1m}\u001b[0m             \u001b[32mspecified in the \u001b[0m            \n",
      "                            \u001b[1m}\u001b[0m,                \u001b[32mrubric.\\n\"incorrect\" \u001b[0m        \n",
      "                            \u001b[33mconfig\u001b[0m=\u001b[1;35mEndpoint\u001b[0m  \u001b[32mmeans that the output\u001b[0m        \n",
      "                                \u001b[33mkind\u001b[0m=\u001b[32m'opena\u001b[0m  \u001b[32mdoes not meet the \u001b[0m           \n",
      "                                \u001b[33murl\u001b[0m=\u001b[32m''\u001b[0m,       \u001b[32mcriteria specified in\u001b[0m        \n",
      "                                \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-\u001b[0m  \u001b[32mthe rubric.\\n'\u001b[0m,              \n",
      "                                \u001b[33madditional_\u001b[0m                  \u001b[33mrail\u001b[0m        \n",
      "                                \u001b[33mprovider\u001b[0m=\u001b[3;35mNo\u001b[0m                      \u001b[32m\u001b[0m        \n",
      "                                \u001b[33mtemperature\u001b[0m  \u001b[3;92mTrue\u001b[0m,                        \n",
      "                                \u001b[33mmax_tokens\u001b[0m=\u001b[3;35m\u001b[0m                      \u001b[32m\u001b[0m        \n",
      "                                \u001b[33mtop_k\u001b[0m=\u001b[1;36m3\u001b[0m,      \u001b[3;91mFalse\u001b[0m                        \n",
      "                                \u001b[33muse_ranker\u001b[0m=\u001b[3;92m\u001b[0m                  \u001b[1m}\u001b[0m            \n",
      "                                \u001b[33mcollection_\u001b[0m              \u001b[1m)\u001b[0m                \n",
      "                            \u001b[1m)\u001b[0m                         \u001b[1m)\u001b[0m                    \n",
      "                        \u001b[1m)\u001b[0m                         \u001b[1m)\u001b[0m,                       \n",
      "                                                  \u001b[1;35mAssertionLLM\u001b[0m\u001b[1m(\u001b[0m            \n",
      "                                                      \u001b[33mresult\u001b[0m=\u001b[3;91mFalse\u001b[0m,        \n",
      "                                                      \u001b[33mllm_metric\u001b[0m=\u001b[32m'\u001b[0m        \n",
      "                                                      \u001b[33mreference\u001b[0m=\u001b[32m''\u001b[0m,        \n",
      "                                                      \u001b[33massertion\u001b[0m=\u001b[32m'T\u001b[0m        \n",
      "                                              \u001b[32mshould be a report on\u001b[0m        \n",
      "                                              \u001b[32mtaxes.'\u001b[0m,                     \n",
      "                                                      \u001b[33mmetric_evalu\u001b[0m        \n",
      "                                                          \u001b[33meval_end\u001b[0m        \n",
      "                                                              \u001b[33mconn\u001b[0m        \n",
      "                                                                  \u001b[33m\u001b[0m        \n",
      "                                                                          \n",
      "                                                                          \n",
      "                                                                          \n",
      "                                                                  \u001b[1m\u001b[0m        \n",
      "                                                                  \u001b[33m\u001b[0m        \n",
      "                                                              \u001b[1m)\u001b[0m,           \n",
      "                                                              \u001b[33mconf\u001b[0m        \n",
      "                                                                  \u001b[33m\u001b[0m        \n",
      "                                                                  \u001b[33m\u001b[0m        \n",
      "                                                                  \u001b[33m\u001b[0m        \n",
      "                                                                  \u001b[33m\u001b[0m        \n",
      "                                                                  \u001b[33m\u001b[0m        \n",
      "                                                                  \u001b[33m\u001b[0m        \n",
      "                                                                  \u001b[33m\u001b[0m        \n",
      "                                                                  \u001b[33m\u001b[0m        \n",
      "                                                                  \u001b[33m\u001b[0m        \n",
      "                                                                  \u001b[33m\u001b[0m        \n",
      "                                                              \u001b[1m)\u001b[0m            \n",
      "                                                          \u001b[1m)\u001b[0m,               \n",
      "                                                          \u001b[33mmetric\u001b[0m=\u001b[1;35mM\u001b[0m        \n",
      "                                                              \u001b[33mprom\u001b[0m        \n",
      "                                              \u001b[32mare grading output \u001b[0m          \n",
      "                                              \u001b[32maccording to a \u001b[0m              \n",
      "                                              \u001b[32muser-specified \u001b[0m              \n",
      "                                              \u001b[32mrubric. If the \u001b[0m              \n",
      "                                              \u001b[32mstatement in the \u001b[0m            \n",
      "                                              \u001b[32mrubric is true, then \u001b[0m        \n",
      "                                              \u001b[32mthe output passes the\u001b[0m        \n",
      "                                              \u001b[32mtest.\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEXAMPLES\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\\u001b[0m        \n",
      "                                              \u001b[32mHello \u001b[0m                       \n",
      "                                              \u001b[32mworld\\n************\\\u001b[0m        \n",
      "                                              \u001b[32mContent contains a \u001b[0m          \n",
      "                                              \u001b[32mgreeting\\n**********\u001b[0m        \n",
      "                                              \u001b[32mAvast ye swabs, repel\u001b[0m        \n",
      "                                              \u001b[32mthe \u001b[0m                         \n",
      "                                              \u001b[32minvaders!\\n*********\u001b[0m        \n",
      "                                              \u001b[32mDoes not speak like a\u001b[0m        \n",
      "                                              \u001b[32mpirate\\n************\u001b[0m        \n",
      "                                              \u001b[32mEXAMPLES\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mBEGIN \u001b[0m         \n",
      "                                              \u001b[32mDATA\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: \u001b[0m            \n",
      "                                              \u001b[32m{\u001b[0m\u001b[32moutput\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n**********\u001b[0m        \n",
      "                                              \u001b[32m{\u001b[0m\u001b[32massertion\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n*******\u001b[0m        \n",
      "                                              \u001b[32mDATA\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\nYour \u001b[0m               \n",
      "                                              \u001b[32mresponse must be a \u001b[0m          \n",
      "                                              \u001b[32msingle word, either \u001b[0m         \n",
      "                                              \u001b[32m\"correct\" or \u001b[0m                \n",
      "                                              \u001b[32m\"incorrect\", and \u001b[0m            \n",
      "                                              \u001b[32mshould not contain \u001b[0m          \n",
      "                                              \u001b[32many text or \u001b[0m                 \n",
      "                                              \u001b[32mcharacters aside from\u001b[0m        \n",
      "                                              \u001b[32mthat word.\\n\"correct\"\u001b[0m        \n",
      "                                              \u001b[32mmeans that the output\u001b[0m        \n",
      "                                              \u001b[32mmeets the criteria \u001b[0m          \n",
      "                                              \u001b[32mspecified in the \u001b[0m            \n",
      "                                              \u001b[32mrubric.\\n\"incorrect\" \u001b[0m        \n",
      "                                              \u001b[32mmeans that the output\u001b[0m        \n",
      "                                              \u001b[32mdoes not meet the \u001b[0m           \n",
      "                                              \u001b[32mcriteria specified in\u001b[0m        \n",
      "                                              \u001b[32mthe rubric.\\n'\u001b[0m,              \n",
      "                                                              \u001b[33mrail\u001b[0m        \n",
      "                                                                  \u001b[32m\u001b[0m        \n",
      "                                              \u001b[3;92mTrue\u001b[0m,                        \n",
      "                                                                  \u001b[32m\u001b[0m        \n",
      "                                              \u001b[3;91mFalse\u001b[0m                        \n",
      "                                                              \u001b[1m}\u001b[0m            \n",
      "                                                          \u001b[1m)\u001b[0m                \n",
      "                                                      \u001b[1m)\u001b[0m                    \n",
      "                                                  \u001b[1m)\u001b[0m                        \n",
      "                                              \u001b[1m]\u001b[0m                            \n",
      "\n",
      " \u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m           \u001b[1;35mResponseModel\u001b[0m\u001b[1m(\u001b[0m        \u001b[1m[\u001b[0m                      \u001b[32mOK\u001b[0m    \n",
      "     \u001b[33mmessage\u001b[0m=\u001b[32m'What is \u001b[0m      \u001b[33mmessage\u001b[0m=\u001b[32m'The \u001b[0m         \u001b[1;35mAssertionDetermi\u001b[0m        \n",
      " \u001b[32mthe capital of \u001b[0m        \u001b[32mcapital of France is\u001b[0m          \u001b[33mresult\u001b[0m=\u001b[3;92mTrue\u001b[0m,         \n",
      " \u001b[32mFrance?'\u001b[0m               \u001b[32mParis.'\u001b[0m,                      \u001b[33mkind\u001b[0m=\u001b[32m'contai\u001b[0m        \n",
      " \u001b[1m)\u001b[0m                          \u001b[33mstats\u001b[0m=\u001b[1;35mResponseS\u001b[0m          \u001b[33massertion\u001b[0m=\u001b[32m'P\u001b[0m        \n",
      "                                \u001b[33mtokens_requ\u001b[0m      \u001b[1m)\u001b[0m                        \n",
      "                                \u001b[33mtokens_resp\u001b[0m  \u001b[1m]\u001b[0m                            \n",
      "                                \u001b[33mtokens_tota\u001b[0m                               \n",
      "                                \u001b[33mconn_start_\u001b[0m                               \n",
      "                                \u001b[33mconn_end_ti\u001b[0m                               \n",
      "                                \u001b[33mconn_durati\u001b[0m                               \n",
      "                            \u001b[1m)\u001b[0m,                                             \n",
      "                            \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-AB\u001b[0m                               \n",
      "                            \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m                                      \n",
      "                                \u001b[1m{\u001b[0m                                          \n",
      "                                    \u001b[32m'finish\u001b[0m                               \n",
      "                        \u001b[32m'stop'\u001b[0m,                                            \n",
      "                                    \u001b[32m'index'\u001b[0m:                               \n",
      "                        \u001b[1;36m0\u001b[0m,                                                 \n",
      "                                    \u001b[32m'logpro\u001b[0m                               \n",
      "                        \u001b[3;35mNone\u001b[0m,                                              \n",
      "                                    \u001b[32m'messag\u001b[0m                               \n",
      "                        \u001b[1m{\u001b[0m                                                  \n",
      "                                        \u001b[32m'co\u001b[0m                               \n",
      "                        \u001b[32m'The capital of \u001b[0m                                   \n",
      "                        \u001b[32mFrance is Paris.'\u001b[0m,                                 \n",
      "                                        \u001b[32m'ro\u001b[0m                               \n",
      "                        \u001b[32m'assistant'\u001b[0m,                                       \n",
      "                                        \u001b[32m're\u001b[0m                               \n",
      "                        \u001b[3;35mNone\u001b[0m                                               \n",
      "                                    \u001b[1m}\u001b[0m                                      \n",
      "                                \u001b[1m}\u001b[0m                                          \n",
      "                            \u001b[1m]\u001b[0m,                                             \n",
      "                            \u001b[33mcreated\u001b[0m=\u001b[1;36m1727356\u001b[0m                               \n",
      "                            \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-m\u001b[0m                               \n",
      "                            \u001b[33mobject\u001b[0m=\u001b[32m'chat.co\u001b[0m                               \n",
      "                            \u001b[33msystem_fingerpr\u001b[0m                               \n",
      "                            \u001b[33musage\u001b[0m=\u001b[1m{\u001b[0m                                        \n",
      "                                \u001b[32m'completion\u001b[0m                               \n",
      "                        \u001b[1;36m7\u001b[0m,                                                 \n",
      "                                \u001b[32m'prompt_tok\u001b[0m                               \n",
      "                        \u001b[1;36m14\u001b[0m,                                                \n",
      "                                \u001b[32m'total_toke\u001b[0m                               \n",
      "                        \u001b[1;36m21\u001b[0m,                                                \n",
      "                                \u001b[32m'completion\u001b[0m                               \n",
      "                        \u001b[1m{\u001b[0m                                                  \n",
      "                                    \u001b[32m'reason\u001b[0m                               \n",
      "                        \u001b[1;36m0\u001b[0m                                                  \n",
      "                                \u001b[1m}\u001b[0m                                          \n",
      "                            \u001b[1m}\u001b[0m,                                             \n",
      "                            \u001b[33mconfig\u001b[0m=\u001b[1;35mEndpoint\u001b[0m                               \n",
      "                                \u001b[33mkind\u001b[0m=\u001b[32m'opena\u001b[0m                               \n",
      "                                \u001b[33murl\u001b[0m=\u001b[32m''\u001b[0m,                                    \n",
      "                                \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-\u001b[0m                               \n",
      "                                \u001b[33madditional_\u001b[0m                               \n",
      "                                \u001b[33mprovider\u001b[0m=\u001b[3;35mNo\u001b[0m                               \n",
      "                                \u001b[33mtemperature\u001b[0m                               \n",
      "                                \u001b[33mmax_tokens\u001b[0m=\u001b[3;35m\u001b[0m                               \n",
      "                                \u001b[33mtop_k\u001b[0m=\u001b[1;36m3\u001b[0m,                                   \n",
      "                                \u001b[33muse_ranker\u001b[0m=\u001b[3;92m\u001b[0m                               \n",
      "                                \u001b[33mcollection_\u001b[0m                               \n",
      "                            \u001b[1m)\u001b[0m                                              \n",
      "                        \u001b[1m)\u001b[0m                                                  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can also run contextcheck in a command line\n",
    "!ccheck --output-type console --filename ../tests/scenario_example1.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
